{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability Verification for an Inverted Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "import safe_learning\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas\n",
    "import os\n",
    "\n",
    "from scipy.linalg import block_diag\n",
    "from utilities import InvertedPendulum, debug\n",
    "from safe_learning.utilities import get_storage, set_storage\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "%matplotlib inline\n",
    "    \n",
    "NP_DTYPE = safe_learning.config.np_dtype\n",
    "TF_DTYPE = safe_learning.config.dtype\n",
    "_STORAGE = {}\n",
    "EPS = 1e-8\n",
    "\n",
    "HEAT_MAP = plt.get_cmap('inferno', lut=None)\n",
    "HEAT_MAP.set_over((1., 1., 1., 0.))\n",
    "HEAT_MAP.set_under('black')\n",
    "\n",
    "LEVEL_MAP = plt.get_cmap('viridis', lut=15)\n",
    "LEVEL_MAP.set_over('gold')\n",
    "LEVEL_MAP.set_under('white')\n",
    "\n",
    "BINARY_MAP = ListedColormap([(1., 1., 1., 0.), (0., 1., 0., 0.65)])\n",
    "\n",
    "pandas.options.display.float_format = '{:,.4f}'.format\n",
    "pandas.set_option('expand_frame_repr', False)\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "\n",
    "# TODO testing ****************************************#\n",
    "\n",
    "class Options(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Options, self).__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "OPTIONS = Options(np_dtype              = safe_learning.config.np_dtype,\n",
    "                  tf_dtype              = safe_learning.config.dtype,\n",
    "                  use_linear_dynamics   = False,\n",
    "                  saturate              = True,\n",
    "                  eps                   = 1e-8,\n",
    "                  dpi                   = 100,\n",
    "                  fontproperties        = FontProperties(size=16),\n",
    "                  save_figs             = False\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CPU_COUNT = os.cpu_count()\n",
    "NUM_CORES = 8\n",
    "NUM_SOCKETS = 2\n",
    "\n",
    "os.environ[\"KMP_BLOCKTIME\"]    = str(0)\n",
    "os.environ[\"KMP_SETTINGS\"]     = str(1)\n",
    "os.environ[\"KMP_AFFINITY\"]     = 'granularity=fine,noverbose,compact,1,0'\n",
    "os.environ[\"OMP_NUM_THREADS\"]  = str(NUM_CORES)\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads  = NUM_CORES,\n",
    "                        inter_op_parallelism_threads  = NUM_SOCKETS,\n",
    "                        allow_soft_placement          = False,\n",
    "#                         log_device_placement          = True,\n",
    "                        device_count                  = {'CPU': MAX_CPU_COUNT},\n",
    "                       )\n",
    "\n",
    "# TODO manually for CPU-only?\n",
    "config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\n",
    "\n",
    "try:\n",
    "    session.close()\n",
    "except NameError:\n",
    "    pass\n",
    "session = tf.InteractiveSession(config=config)\n",
    "\n",
    "# print('Found MAX_CPU_COUNT =', MAX_CPU_COUNT)\n",
    "# for dev in session.list_devices():\n",
    "#     print(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saturate the action so that it lies in [-1, 1]\n",
    "SATURATE = True\n",
    "\n",
    "# Use the true physical parameters in the GP model\n",
    "USE_TRUE_PARAMETERS = False\n",
    "\n",
    "# Use the linearized discrete-time model as the true underlying dynamics\n",
    "USE_LINEAR_DYNAMICS = False\n",
    "\n",
    "# Use a threshold of zero when checking for stability\n",
    "USE_ZERO_THRESHOLD = False\n",
    "\n",
    "#\n",
    "USE_LINEAR_KERNELS = False\n",
    "\n",
    "#\n",
    "USE_LIPSCHITZ_SCALING = True\n",
    "\n",
    "# Scaling factor for GP confidence intervals\n",
    "BETA = 2.\n",
    "\n",
    "#\n",
    "TRAIN_HYPERPARAMETERS = False\n",
    "\n",
    "#\n",
    "GP_SCALING = 1.\n",
    "\n",
    "#\n",
    "NOISE_VAR = 0.001 ** 2\n",
    "\n",
    "#\n",
    "ADAPTIVE = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "dt = 0.01   # sampling time\n",
    "g = 9.81    # gravity\n",
    "\n",
    "# True system parameters\n",
    "m = 0.15    # pendulum mass\n",
    "L = 0.5     # pole length\n",
    "b = 0.1     # rotational friction\n",
    "\n",
    "# State and action normalizers\n",
    "theta_max = np.deg2rad(30)\n",
    "omega_max = np.sqrt(g / L)\n",
    "u_max = g * m * L * np.sin(theta_max)\n",
    "\n",
    "state_norm = (theta_max, omega_max)\n",
    "action_norm = (u_max, )\n",
    "\n",
    "# Constraints for initial 'safe' states\n",
    "theta_safe = np.deg2rad(8)\n",
    "omega_safe = 0.5*np.sqrt(g / L)\n",
    "\n",
    "# Dimensions and domains\n",
    "state_dim = 2\n",
    "action_dim = 1\n",
    "state_limits = np.array([[-1., 1.]] * state_dim)\n",
    "action_limits = np.array([[-1., 1.]] * action_dim)\n",
    "\n",
    "# True system\n",
    "true_pendulum = InvertedPendulum(m, L, b, dt, [state_norm, action_norm])\n",
    "A_true, B_true = true_pendulum.linearize()\n",
    "\n",
    "if USE_LINEAR_DYNAMICS:\n",
    "    true_dynamics = safe_learning.functions.LinearSystem((A_true, B_true), name='true_dynamics')\n",
    "else:\n",
    "    true_dynamics = true_pendulum.__call__\n",
    "\n",
    "# \"Wrong\" system\n",
    "m = 0.1     # pendulum mass\n",
    "L = 0.4     # pole length\n",
    "b = 0.0     # rotational friction\n",
    "pendulum = InvertedPendulum(m, L, b, dt, [state_norm, action_norm])\n",
    "A, B = pendulum.linearize()\n",
    "\n",
    "if USE_TRUE_PARAMETERS:\n",
    "    A = A_true\n",
    "    B = B_true\n",
    "mean_dynamics = safe_learning.LinearSystem((A, B), name='mean_dynamics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_true = np.hstack((A_true, B_true))\n",
    "m = np.hstack((A, B))\n",
    "variances = (m_true - m) ** 2\n",
    "\n",
    "# Make sure at least some non-zero prior variance is maintained\n",
    "np.clip(variances, 1e-3, None, out=variances)\n",
    "\n",
    "# Measurement noise\n",
    "noise_var = NOISE_VAR\n",
    "\n",
    "# Input to GP is of the form (x,u)\n",
    "full_dim = state_dim + action_dim\n",
    "\n",
    "# Kernels\n",
    "if USE_LINEAR_KERNELS:\n",
    "    kernel_theta = gpflow.kernels.Linear(full_dim, variance=variances[0, :], ARD=True)\n",
    "\n",
    "    kernel_omega = gpflow.kernels.Linear(full_dim, variance=variances[1, :], ARD=True)\n",
    "\n",
    "else:\n",
    "    kernel_theta = (gpflow.kernels.Linear(full_dim, variance=variances[0, :], ARD=True)\n",
    "                    + gpflow.kernels.Matern32(1, lengthscales=1, active_dims=[0])\n",
    "                    * gpflow.kernels.Linear(1, variance=variances[0, 1]))\n",
    "\n",
    "    kernel_omega = (gpflow.kernels.Linear(full_dim, variance=variances[1, :], ARD=True)\n",
    "                    + gpflow.kernels.Matern32(1, lengthscales=1, active_dims=[0])\n",
    "                    * gpflow.kernels.Linear(1, variance=variances[1, 1]))\n",
    "\n",
    "# Mean dynamics\n",
    "mean_function_theta = safe_learning.LinearSystem((A[[0], :], B[[0], :]), name='mean_dynamics_theta')\n",
    "mean_function_omega = safe_learning.LinearSystem((A[[1], :], B[[1], :]), name='mean_dynamics_omega')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a GP model over the dynamics\n",
    "X_init = np.zeros((1, full_dim), dtype=NP_DTYPE)\n",
    "Y_init = np.zeros((1, 1), dtype=NP_DTYPE)\n",
    "\n",
    "gp_theta = gpflow.gpr.GPR(X_init, Y_init, kernel_theta, mean_function_theta)\n",
    "gp_omega = gpflow.gpr.GPR(X_init, Y_init, kernel_omega, mean_function_omega)\n",
    "\n",
    "\n",
    "# TODO Tensorflow spits out a lot of allocator errors when creating 0-length dataholders in gpflow. Occurs when:\n",
    "#     - initializing with empty data matrices X and Y\n",
    "#     - using GPRCached (initializes empty dataholders for Cholesky decomposition)\n",
    "\n",
    "# X_init = np.empty((0, full_dim), dtype=NP_DTYPE)\n",
    "# Y_init = np.empty((0, 1), dtype=NP_DTYPE)\n",
    "# gp_theta = safe_learning.GPRCached(X_init, Y_init, kernel_theta, mean_function_theta)\n",
    "# gp_omega = safe_learning.GPRCached(X_init, Y_init, kernel_omega, mean_function_omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_theta.likelihood.variance = noise_var\n",
    "gp_omega.likelihood.variance = noise_var\n",
    "\n",
    "gp_theta_fun = safe_learning.GaussianProcess(gp_theta, BETA)\n",
    "gp_omega_fun = safe_learning.GaussianProcess(gp_omega, BETA)\n",
    "\n",
    "# Stack GP functions => block-diagonal kernel matrix\n",
    "dynamics = safe_learning.FunctionStack((gp_theta_fun, gp_omega_fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of states along each dimension\n",
    "if ADAPTIVE:\n",
    "    num_states = 501\n",
    "else:\n",
    "    num_states = 3001\n",
    "\n",
    "# State grid\n",
    "limits = np.array([[-1., 1.], [-1., 1.]])\n",
    "grid = safe_learning.GridWorld(limits, num_states)\n",
    "\n",
    "# Discretization constant\n",
    "if USE_ZERO_THRESHOLD:\n",
    "    disc_constant = 0.0\n",
    "else:\n",
    "    disc_constant = np.sum(grid.unit_maxes) / 2\n",
    "\n",
    "print('Grid size: {}'.format(grid.nindex))\n",
    "print('Discretization constant: {}'.format(disc_constant))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy\n",
    "\n",
    "Fix the policy to the LQR solution for the true system, possibly with saturation constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State cost matrix\n",
    "Q = np.diag([1., 2.])\n",
    "\n",
    "# Action cost matrix\n",
    "R = 1.2*np.identity(action_dim)\n",
    "\n",
    "# Normalize cost matrices\n",
    "cost_norm = np.amax([Q.max(), R.max()])\n",
    "Q = Q / cost_norm\n",
    "R = R / cost_norm\n",
    "\n",
    "# Quadratic cost function\n",
    "cost_function = safe_learning.QuadraticFunction(block_diag(Q, R), name='cost_function')\n",
    "\n",
    "# Solve the LQR problem for the true system\n",
    "K, P = safe_learning.utilities.dlqr(A_true, B_true, Q, R)\n",
    "policy = safe_learning.LinearSystem(-K, name='policy')\n",
    "\n",
    "if SATURATE:\n",
    "    policy = safe_learning.Saturation(policy, -1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_policy(policy, grid, norms, tol=1e-10):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=OPTIONS.dpi)\n",
    "    ticks = np.linspace(-1., 1., 9)\n",
    "    cutoff = 1. - tol\n",
    "    plot_limits = np.asarray(norms).reshape((-1, 1)) * grid.limits\n",
    "    \n",
    "    z = policy(grid.all_points).eval().reshape(grid.num_points)\n",
    "    im = ax.imshow(z.T, origin='lower', extent=plot_limits.ravel(), aspect=plot_limits[0, 1] / plot_limits[1, 1], cmap=HEAT_MAP, vmin=-cutoff, vmax=cutoff)\n",
    "    cbar = fig.colorbar(im, ax=ax, label=r'$u = \\pi(x)$', ticks=ticks)\n",
    "    ax.set_xlabel(r'$\\phi$ [deg]')\n",
    "    ax.set_ylabel(r'$\\dot{\\phi}$ [deg/s]')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize policy\n",
    "norms = np.rad2deg(state_norm)\n",
    "plot_policy(policy, grid, norms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyapunov Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Lyapunov function corresponding to the known policy\n",
    "lyapunov_function = safe_learning.QuadraticFunction(P)\n",
    "grad_lyapunov_function = safe_learning.LinearSystem((2*P,))\n",
    "\n",
    "# Lipschitz constants\n",
    "L_pol = np.linalg.norm(-K, ord=1)\n",
    "L_dyn = np.linalg.norm(A_true, ord=1) + np.linalg.norm(B_true, ord=1) * L_pol\n",
    "\n",
    "if USE_LIPSCHITZ_SCALING:\n",
    "    L_v = lambda x: tf.abs(grad_lyapunov_function(x))\n",
    "else:\n",
    "    L_v = lambda x: tf.norm(grad_lyapunov_function(x), ord=1, axis=1, keep_dims=True)\n",
    "    \n",
    "# Set initial safe set as a small level set of the Lyapunov function\n",
    "values = lyapunov_function(grid.all_points).eval()\n",
    "cutoff = 3e-3 * np.max(values)\n",
    "initial_safe_set = np.squeeze(values, axis=1) <= cutoff\n",
    "\n",
    "# Set initial safe set as a hypercube in the state space\n",
    "# safe_norm = np.array([[theta_safe / theta_max, omega_safe / omega_max]])\n",
    "# norm_states = state_discretization.all_points / safe_norm\n",
    "# initial_safe_set = np.all(np.logical_and(norm_states >= -1, norm_states <= 1), axis=1, keepdims=False)\n",
    "\n",
    "# Initialize class\n",
    "lyapunov = safe_learning.Lyapunov(grid, lyapunov_function, dynamics, L_dyn, L_v, disc_constant, policy, initial_safe_set, adaptive=ADAPTIVE)\n",
    "lyapunov.update_values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = get_storage(_STORAGE)\n",
    "if storage is None:\n",
    "    # Current\n",
    "    states = tf.placeholder(OPTIONS.tf_dtype, shape=[None, lyapunov.discretization.ndim], name='states')\n",
    "    actions = policy(states)\n",
    "    values = lyapunov.lyapunov_function(states)\n",
    "    \n",
    "    # Predicted future\n",
    "    future_states_mean, future_states_error = lyapunov.dynamics(states, actions)\n",
    "    future_values_mean = lyapunov.lyapunov_function(future_states_mean)\n",
    "    lv = lyapunov.lipschitz_lyapunov(future_states_mean)\n",
    "    future_values_error = tf.reduce_sum(lv * future_states_error, axis=1, keepdims=True)\n",
    "    dv_mean = future_values_mean - values\n",
    "    dv_bound = dv_mean + future_values_error\n",
    "    \n",
    "    # True future\n",
    "    future_states = true_dynamics(states, actions)\n",
    "    future_values = lyapunov.lyapunov_function(future_states)\n",
    "    dv = future_values - values\n",
    "    \n",
    "    # Discretization effects\n",
    "    tau = tf.placeholder(OPTIONS.tf_dtype, shape=[None, 1], name='discretization_constant')\n",
    "    threshold = lyapunov.threshold(states, tau)\n",
    "    negative = tf.less(dv_bound, threshold)\n",
    "    \n",
    "    # Place into storage\n",
    "    storage = [('states', states), ('actions', actions), ('values', values), \n",
    "               ('future_states', future_states), ('future_values', future_values), ('dv', dv),\n",
    "               ('tau', tau), ('threshold', threshold), ('negative', negative)]\n",
    "    set_storage(_STORAGE, storage)\n",
    "else:\n",
    "    # Get from storage\n",
    "    states, actions, values, future_states, future_values, dv, tau, threshold, negative  = storage.values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Discretization Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 18\n",
    "plt.rc('font', size=fontsize)\n",
    "\n",
    "feed_dict = {states: grid.all_points, tau: [[lyapunov.tau]]}\n",
    "plot_limits = np.asarray(norms).reshape((-1, 1)) * grid.limits\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 15), dpi=OPTIONS.dpi)\n",
    "fig.subplots_adjust(wspace=0.15, hspace=0.3)\n",
    "vmin = -2\n",
    "\n",
    "ax = axes[0, 0]\n",
    "z = dv.eval(feed_dict).reshape(grid.num_points)\n",
    "im = ax.imshow(z.T, origin='lower', extent=plot_limits.ravel(), aspect=plot_limits[0, 1] / plot_limits[1, 1], cmap=HEAT_MAP, vmin=vmin, vmax=0)\n",
    "cbar = fig.colorbar(im, ax=ax, label=r'$v(f_\\pi(x)) - v(x)$', ticks=[-2, -1.5, -1, -0.5, 0])\n",
    "ax.set_title(r'No discretization ($\\tau = 0$)', fontsize=fontsize)\n",
    "ax.set_xlabel(r'$\\phi$ [deg]')\n",
    "ax.set_ylabel(r'$\\dot{\\phi}$ [deg/s]')\n",
    "yticks = cbar.ax.get_yticks()\n",
    "tick_labels = ['{:.1f}'.format((1 - y) * vmin) for y in yticks]\n",
    "tick_labels[-1] = r'$\\geq 0$'\n",
    "cbar.ax.set_yticklabels(tick_labels)\n",
    "\n",
    "\n",
    "for ax, M in zip(axes.ravel()[1:], [3001, 1001, 501]):\n",
    "    disc = safe_learning.GridWorld(grid.limits, M)\n",
    "    feed_dict[states] = disc.all_points\n",
    "    feed_dict[tau] = [[np.sum(disc.unit_maxes) / 2]]\n",
    "    \n",
    "    z = (dv - threshold).eval(feed_dict).reshape(disc.num_points)\n",
    "    im = ax.imshow(z.T, origin='lower', extent=plot_limits.ravel(), aspect=plot_limits[0, 1] / plot_limits[1, 1], cmap=HEAT_MAP, vmin=vmin, vmax=0)\n",
    "    cbar = fig.colorbar(im, ax=ax, label=r'$v(f_\\pi(x)) - v(x) + L_{\\Delta v}\\tau$', ticks=[-2, -1.5, -1, -0.5, 0])\n",
    "    ax.set_title(r'$M = {}$'.format(M - 1) + ',  ' + r'$|\\mathcal{X}_\\tau|$ = ' + r'{:.1e}'.format(disc.nindex) \n",
    "                 + ',  ' + r'$\\tau$ = ' + r'{:.0e}'.format(np.sum(disc.unit_maxes) / 2), fontsize=fontsize)\n",
    "    ax.set_xlabel(r'$\\phi$ [deg]')\n",
    "    ax.set_ylabel(r'$\\dot{\\phi}$ [deg/s]')\n",
    "    \n",
    "    yticks = cbar.ax.get_yticks()\n",
    "    tick_labels = ['{:.1f}'.format((1 - y) * vmin) for y in yticks]\n",
    "    tick_labels[-1] = r'$\\geq 0$'\n",
    "    cbar.ax.set_yticklabels(tick_labels)\n",
    "    \n",
    "# cbar.ax.get_ymajorticklabels()[0] = '5'\n",
    "# fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if OPTIONS.save_figs:\n",
    "    fig.savefig('figures/pendulum_basic_grid_effect.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 18\n",
    "plt.rc('font', size=fontsize)\n",
    "\n",
    "limits = np.array([[-1., 1.], [-1., 1.]])\n",
    "grid = safe_learning.GridWorld(limits, 501)\n",
    "\n",
    "Nmax = 16\n",
    "cmap = plt.get_cmap('viridis', lut=Nmax)\n",
    "cmap.set_over('gold')\n",
    "cmap.set_under((1., 1., 1., 0.))\n",
    "\n",
    "# Adaptive discretization\n",
    "feed_dict = {states: grid.all_points, tau: [[np.sum(grid.unit_maxes) / 2]]}\n",
    "N = (threshold / dv).eval(feed_dict)\n",
    "N[np.isnan(N)] = -1\n",
    "N[N < 0] = -1\n",
    "N = np.ceil(N)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10), dpi=OPTIONS.dpi)\n",
    "\n",
    "z = N.reshape(grid.num_points)\n",
    "im = ax.imshow(z.T, origin='lower', extent=plot_limits.ravel(), aspect=plot_limits[0, 1] / plot_limits[1, 1], cmap=cmap, vmin=0, vmax=Nmax)\n",
    "cbar = fig.colorbar(im, ax=ax, label=r'$N({\\bf x})$', ticks=np.arange(0, Nmax + 1, 2))\n",
    "ax.set_title(r'$M = {}$'.format(grid.num_points[0] - 1) \n",
    "             + ',  ' + r'$|\\mathcal{X}_\\tau|$ = ' + r'{:.1e}'.format(grid.nindex) \n",
    "             + ',  ' + r'$\\tau$ = ' + r'{:.0e}'.format(np.sum(grid.unit_maxes) / 2), \n",
    "             fontsize=fontsize)\n",
    "ax.set_xlabel(r'$\\phi$ [deg]')\n",
    "ax.set_ylabel(r'$\\dot{\\phi}$ [deg/s]')\n",
    "\n",
    "yticks = cbar.ax.get_yticks()\n",
    "tick_labels = ['{:.0f}'.format(y * Nmax) for y in yticks]\n",
    "tick_labels[-1] = r'$\\geq {}$'.format(Nmax)\n",
    "cbar.ax.set_yticklabels(tick_labels)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "if OPTIONS.save_figs:\n",
    "    fig.savefig('figures/pendulum_adaptive_Nreq.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Safe Set Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare safe set before and after checking the decrease condition for the first time\n",
    "c_max = lyapunov.feed_dict[lyapunov.c_max]\n",
    "init_safe_set_size = np.sum(lyapunov.safe_set)\n",
    "\n",
    "print('Before update ...')\n",
    "print('c_max: {}'.format(c_max))\n",
    "print('Safe set size: {}\\n'.format(init_safe_set_size))\n",
    "\n",
    "old_safe_set = np.copy(lyapunov.safe_set)\n",
    "lyapunov.update_safe_set()\n",
    "\n",
    "c_max = lyapunov.feed_dict[lyapunov.c_max]\n",
    "init_safe_set_size = np.sum(lyapunov.safe_set)\n",
    "\n",
    "print('After update ...')\n",
    "print('c_max: {}'.format(c_max))\n",
    "print('Safe set size: {}'.format(init_safe_set_size))\n",
    "\n",
    "# debug(lyapunov, true_dynamics, state_norm, plot='pendulum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Learning and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action_variation = np.array([-0.01, -0.001, 0.0, 0.001, 0.01], dtype=NP_DTYPE).reshape((-1, 1))\n",
    "action_variation = np.array([[0.]], dtype=NP_DTYPE)\n",
    "\n",
    "with tf.name_scope('add_new_measurement'):\n",
    "    full_dim = state_dim + action_dim \n",
    "    tf_max_state_action = tf.placeholder(TF_DTYPE, shape=[1, full_dim])\n",
    "    tf_measurement = true_dynamics(tf_max_state_action)\n",
    "    \n",
    "def update_gp():\n",
    "    \"\"\"Update the GP model based on an actively selected data point.\"\"\"\n",
    "    \n",
    "    # Get a new sample location\n",
    "    max_state_action, _ = safe_learning.get_safe_sample(lyapunov, action_variation, action_limits, positive=True, num_samples=1000)\n",
    "    \n",
    "    # Obtain a measurement of the true dynamics\n",
    "    lyapunov.feed_dict[tf_max_state_action] = max_state_action\n",
    "    measurement = tf_measurement.eval(feed_dict=lyapunov.feed_dict)\n",
    "    \n",
    "    # Add the measurement to our GP dynamics\n",
    "    lyapunov.dynamics.add_data_point(max_state_action, measurement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_update = 10\n",
    "safe_set_updates = 3\n",
    "\n",
    "can_shrink          = True\n",
    "n_max               = 16\n",
    "safety_factor       = 1.\n",
    "parallel_iterations = NUM_CORES\n",
    "\n",
    "try:\n",
    "    e = len(level) - 1\n",
    "    level = np.concatenate((level, np.zeros(safe_set_updates)))\n",
    "    safe_size = np.concatenate((safe_size, np.zeros(safe_set_updates)))\n",
    "    temp = data_per_update * np.arange(1, safe_set_updates + 1) + data_size[-1]\n",
    "    data_size = np.concatenate((data_size, temp))\n",
    "except NameError:\n",
    "    e = 0\n",
    "    level = np.zeros(safe_set_updates + 1)\n",
    "    level[0] = lyapunov.feed_dict[lyapunov.c_max]\n",
    "    safe_size = np.zeros(safe_set_updates + 1)\n",
    "    safe_size[0] = np.sum(lyapunov.safe_set)\n",
    "    data_size = data_per_update * np.arange(safe_set_updates + 1)\n",
    "    \n",
    "for i in range(safe_set_updates):\n",
    "    print('Iteration {} with c_max: {}'.format(e + i + 1, lyapunov.feed_dict[lyapunov.c_max]))\n",
    "\n",
    "    start = time.time()\n",
    "    for _ in range(data_per_update): \n",
    "        update_gp()\n",
    "    end = time.time()\n",
    "    duration_gp = end - start\n",
    "    \n",
    "    start = time.time()\n",
    "    lyapunov.update_safe_set(can_shrink, n_max, safety_factor, parallel_iterations)\n",
    "    end = time.time()\n",
    "    duration_lyap = end - start\n",
    "    \n",
    "    level[e + i + 1] = lyapunov.feed_dict[lyapunov.c_max]\n",
    "    safe_size[e + i + 1] = np.sum(lyapunov.safe_set)\n",
    "    \n",
    "    num_data = lyapunov.dynamics.functions[0].X.shape[0]\n",
    "    num_disc = np.prod(lyapunov.discretization.num_points)\n",
    "    num_safe = np.sum(lyapunov.safe_set)\n",
    "    \n",
    "    print(\"Data points collected: {}\".format(num_data))\n",
    "    print('Discretization size: {}'.format(num_disc))\n",
    "    print('Safe set size: {} ({:.2f}%)'.format(num_safe, 100 * num_safe / num_disc))\n",
    "    print('Growth: {}'.format(num_safe - init_safe_set_size))\n",
    "    print('Duration (gp, avg): {}'.format(duration_gp / data_per_update))\n",
    "    print('Duration (lyap): {}'.format(duration_lyap))\n",
    "    print(\"NEW C_MAX: {}\".format(lyapunov.feed_dict[lyapunov.c_max]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 18\n",
    "plt.rc('font', size=fontsize)\n",
    "\n",
    "N = np.copy(lyapunov._n)\n",
    "num_states = len(N)\n",
    "num_refined_states = np.sum(N[N > 1] ** state_dim)\n",
    "print('Grid size:', num_states)\n",
    "print('Safe set size:', num_safe)\n",
    "print('Refined grids size:', num_refined_states)\n",
    "print('Effective total grid size:', num_refined_states + num_states)\n",
    "print('Effective safe grid size:', num_refined_states + num_safe)\n",
    "\n",
    "# debug(lyapunov, true_dynamics, state_norm, Nmax=128, plot='pendulum')\n",
    "\n",
    "#\n",
    "disc = lyapunov.discretization\n",
    "feed_dict = {states: disc.all_points, tau: [[lyapunov.tau]]}\n",
    "plot_limits = np.asarray(norms).reshape((-1, 1)) * disc.limits\n",
    "\n",
    "#\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10), dpi=OPTIONS.dpi)\n",
    "\n",
    "#\n",
    "decrease_region = (dv.eval(feed_dict) < 0).reshape(disc.num_points)\n",
    "cmap = ListedColormap([(1., 1., 1., 0.), 'lightgrey'])\n",
    "im = ax.imshow(decrease_region.T, origin='lower', extent=plot_limits.ravel(), aspect=plot_limits[0, 1] / plot_limits[1, 1], cmap=cmap, vmin=0, vmax=None)\n",
    "\n",
    "#\n",
    "N = np.copy(lyapunov._n)\n",
    "vals = values.eval(feed_dict).ravel()\n",
    "\n",
    "# TODO\n",
    "N[np.logical_and(vals <= lyapunov.feed_dict[lyapunov.c_max], N <= 0)] = 1\n",
    "N[N == 0] = -1\n",
    "\n",
    "z = N.reshape(disc.num_points)\n",
    "cmap = plt.get_cmap('viridis', lut=n_max)\n",
    "cmap.set_over('gold')\n",
    "cmap.set_under((1., 1., 1., 0.))\n",
    "im = ax.imshow(z.T, origin='lower', extent=plot_limits.ravel(), aspect=plot_limits[0, 1] / plot_limits[1, 1], cmap=cmap, vmin=0, vmax=n_max)\n",
    "if ADAPTIVE:\n",
    "    cbar = fig.colorbar(im, ax=ax, label=r'$N({\\bf x})$', ticks=np.arange(0, Nmax + 1, 2))\n",
    "\n",
    "#\n",
    "initial_safe_set = lyapunov.initial_safe_set.reshape(disc.num_points)\n",
    "cmap = ListedColormap([(1., 1., 1., 0.), (1., 0., 0., 1)])\n",
    "im = ax.imshow(initial_safe_set.T, origin='lower', extent=plot_limits.ravel(), aspect=plot_limits[0, 1] / plot_limits[1, 1], cmap=cmap, vmin=None, vmax=None)\n",
    "\n",
    "#\n",
    "if isinstance(lyapunov.dynamics, safe_learning.UncertainFunction):\n",
    "    # Skip origin data point\n",
    "    X = norms.ravel() * lyapunov.dynamics.functions[0].X[1:, :disc.ndim]\n",
    "    ax.plot(X[:, 0], X[:, 1], 'x', color='pink', mew=2, ms=8)\n",
    "    \n",
    "#\n",
    "ax.set_title(r'$M = {}$'.format(disc.num_points[0] - 1)\n",
    "             + ',  ' + r'$|\\mathcal{X}_\\tau| =$ ' + r'{:.1e}'.format(disc.nindex)\n",
    "             + ',  ' + r'$\\tau =$ ' + r'{:.0e}'.format(np.sum(disc.unit_maxes) / 2), \n",
    "             fontsize=fontsize)\n",
    "ax.set_xlabel(r'$\\phi$ [deg]')\n",
    "ax.set_ylabel(r'$\\dot{\\phi}$ [deg/s]')\n",
    "\n",
    "    \n",
    "# Legend\n",
    "# red = initial safe set, pink = data points, grey = true decrease region\n",
    "colors = ['red', 'pink', 'lightgrey']\n",
    "proxy = [plt.Rectangle((0,0), 1, 1, fc=c) for c in colors]\n",
    "labels = [r'Initial safe set $\\mathcal{S}^{\\!\\ 0}_\\pi$', r'Measurements ($n = {}$)'.format(len(X)), r'$v(f_{\\pi}({\\bf x})) - v({\\bf x}) < 0$']\n",
    "ax.legend(proxy, labels, loc='upper right', fontsize=13.5)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "if OPTIONS.save_figs:\n",
    "    if ADAPTIVE:\n",
    "        fig.savefig('figures/pendulum_adaptive_learning_n{}.pdf'.format(len(X)), bbox_inches='tight')\n",
    "    else:\n",
    "        fig.savefig('figures/pendulum_learning_n{}.pdf'.format(len(X)), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau1 = np.sum(disc.unit_maxes) / 2\n",
    "tau2 = 2 / (3000 + 1)\n",
    "\n",
    "print(tau1)\n",
    "print(tau2)\n",
    "print(tau1 / tau2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=8)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, sharex=False, figsize=(10, 3), dpi=300)\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.2)\n",
    "\n",
    "ax[0].step(data_size, level, 'o', where='post', linestyle='-')\n",
    "ax[0].set_xlabel(r'Number of data points collected', fontsize=12)\n",
    "ax[0].set_ylabel(r'$c_{max}$', fontsize=12)\n",
    "\n",
    "ax[1].step(data_size, safe_size, 'o', where='post')\n",
    "ax[1].set_xlabel(r'Number of data points collected', fontsize=12)\n",
    "ax[1].set_ylabel(r'Safe set size', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(data_size)\n",
    "print(level)\n",
    "print(safe_size)\n",
    "print(lyapunov.discretization.nindex)\n",
    "print((dv.eval({states: lyapunov.discretization.all_points}) < 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug(lyapunov, true_dynamics, state_norm, do_print=True, newly_safe_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "n = np.array([0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120])\n",
    "\n",
    "# Non-adaptive\n",
    "cmax = np.array([0.844, 0.844, 0.844, 0.844, 0.844, 0.844, 0.8441, 2.4477, 5.3532, 10.0886, 12.8918, 17.5511, 22.1951])\n",
    "safe = np.array([206471, 206471, 206471, 206471, 206471, 206471, 206491, 598687, 1309424, 2422172, 2893935, 3527855, 4030337])\n",
    "grid = 9006001\n",
    "dv_ = 5585468\n",
    "\n",
    "# Adaptive\n",
    "cmax_adapt = np.array([0.844, 2.3248, 5.3878, 10.4285, 15.063, 22.0495, 26.7793, 28.3889, 28.9022, 29.3197, 29.626, 29.9521, 30.1488])\n",
    "safe_adapt = np.array([5731, 15778, 36609, 69101, 89157, 111739, 123486, 127071, 128153, 129054, 129695, 130374, 130781])\n",
    "grid_adapt = 251001\n",
    "dv_adapt = 155482\n",
    "\n",
    "# Legend\n",
    "colors = ['red', 'blue']\n",
    "proxy = [plt.Rectangle((0,0), 1, 1, fc=c) for c in colors]\n",
    "labels = ['Adaptive', 'Non-adaptive']\n",
    "\n",
    "#\n",
    "plt.rc('font', size=15)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5), dpi=100)\n",
    "ax.step(n, cmax, 'bo', where='post', linestyle='--')\n",
    "ax.step(n, cmax_adapt, 'ro', where='post', linestyle='--')\n",
    "ax.set_xlabel(r'$n$')\n",
    "ax.set_ylabel(r'$c_n$')\n",
    "ax.set_ylim([0, None])\n",
    "ax.legend(proxy, labels, loc='upper left', fontsize=13.5)\n",
    "fig.savefig('figures/pendulum_cn.pdf', bbox_inches='tight')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5), dpi=100)\n",
    "ax.step(n, safe / dv_, 'bo', where='post', linestyle='--')\n",
    "ax.step(n, safe_adapt / dv_adapt, 'ro', where='post', linestyle='--')\n",
    "ax.set_xlabel(r'$n$')\n",
    "ax.set_ylabel(r'$|\\mathcal{V}(c_n) \\cap \\mathcal{X}_\\tau|\\ / \\ |\\mathcal{D} \\cap \\mathcal{X}_\\tau|$')\n",
    "ax.set_ylim([0, 1])\n",
    "ax.legend(proxy, labels, loc='upper left', fontsize=13.5)\n",
    "fig.savefig('figures/pendulum_safesize.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
