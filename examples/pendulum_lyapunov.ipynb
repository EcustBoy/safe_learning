{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability Verification for an Inverted Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "from scipy.linalg import block_diag\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "import safe_learning\n",
    "from utilities import InvertedPendulum\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    tqdm = lambda x: x\n",
    "    \n",
    "np_dtype = safe_learning.config.np_dtype\n",
    "tf_dtype = safe_learning.config.dtype\n",
    "\n",
    "try:\n",
    "    session.close()\n",
    "except NameError:\n",
    "    pass\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "initialized = False\n",
    "\n",
    "# TODO debugging **************************************#\n",
    "\n",
    "import pandas\n",
    "from collections import OrderedDict\n",
    "pandas.options.display.float_format = '{:,.4f}'.format\n",
    "pandas.set_option('expand_frame_repr', False)\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Saturate the action so that it lies in [-1, 1]\n",
    "saturate = True\n",
    "\n",
    "# Use the true physical parameters in the GP model\n",
    "use_true_parameters = True\n",
    "\n",
    "# Use the linearized discrete-time model as the true underlying dynamics\n",
    "use_linear_dynamics = True\n",
    "\n",
    "# Ignore the non-zero threshold when checking for stability\n",
    "ignore_threshold = True\n",
    "\n",
    "#\n",
    "use_simplified_kernels = True\n",
    "\n",
    "#\n",
    "use_lipschitz_scaling = False\n",
    "\n",
    "# Scaling factor for GP confidence intervals\n",
    "beta = 2.\n",
    "\n",
    "#******************************************************#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_policy(tf_actions, tf_true_actions, n_points, colors=['r','b'], show=True):\n",
    "    fig = plt.figure(figsize=(3, 3), dpi=200)\n",
    "    fig.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "    xx, yy = np.mgrid[-1:1:np.complex(0, n_points[0]), -1:1:np.complex(0, n_points[1])]\n",
    "\n",
    "    grid = np.column_stack((xx.ravel(), yy.ravel()))\n",
    "    learned_control = session.run(tf_actions, feed_dict={tf_states: grid}).reshape(n_points)\n",
    "    ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "    ax.plot_surface(xx, yy, learned_control, color=colors[0], alpha=0.75)\n",
    "    ax.set_title(r'Control', fontsize=16)\n",
    "    ax.set_xlabel(r'$x$', fontsize=14)\n",
    "    ax.set_ylabel(r'$\\theta$', fontsize=14)\n",
    "    ax.set_zlabel(r'$u$', fontsize=14)\n",
    "#     ax.view_init(elev=20., azim=15.)   \n",
    "    if tf_true_actions is not None:\n",
    "        true_control = session.run(tf_true_actions, feed_dict={tf_states: grid}).reshape(n_points)\n",
    "        ax.plot_surface(xx, yy, true_control, color=colors[1], alpha=0.5)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_safe_set(lyapunov, old_safe_set=None, show=True):\n",
    "    \"\"\"Plot the safe set for a given Lyapunov function.\"\"\"\n",
    "    safe_set = lyapunov.safe_set.reshape(num_states).astype(np_dtype)\n",
    "    if old_safe_set is not None:\n",
    "        old_safe_set = old_safe_set.reshape(num_states).astype(np_dtype)\n",
    "        safe_set += old_safe_set\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "    fig.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_title(r'Safe set')\n",
    "    ax.set_xlabel(r'$\\theta$')\n",
    "    ax.set_ylabel(r'$\\omega$')\n",
    "    im = ax.imshow(safe_set.T,\n",
    "                   origin='lower',\n",
    "                   extent=lyapunov.discretization.limits.ravel())\n",
    "    fig.colorbar(im)\n",
    "    \n",
    "    if isinstance(lyapunov.dynamics, safe_learning.UncertainFunction):\n",
    "        X = lyapunov.dynamics.functions[0].X\n",
    "        plt.plot(X[:, 0], X[:, 1], 'rx')\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def debug(newly_safe_only=True):\n",
    "    print('Policy Lipschitz constant (L_pi): {}'.format(L_pol(0).eval()))\n",
    "    print('Dynamics Lipschitz constant (L_f*(L_pi + 1)): {}'.format(L_dyn(0).eval()))\n",
    "    print('beta: {}'.format(beta))\n",
    "    print('tau: {}'.format(tau))\n",
    "    print('c_n: {}'.format(lyapunov.feed_dict[lyapunov.c_max]))\n",
    "\n",
    "    # True quantities\n",
    "    tf_future_states = true_dynamics(tf_states, tf_actions)             # f(x,u)\n",
    "    tf_vals = lyapunov.lyapunov_function(tf_states)                     # v(x)\n",
    "    tf_true_future_vals = lyapunov.lyapunov_function(tf_future_states)  # v(f(x,u))\n",
    "    tf_true_decrease = lyapunov_function(tf_future_states) - tf_vals    # v(f(x,u)) - v(x)\n",
    "    \n",
    "    # Only consider those states that become safe by updating the model\n",
    "    if newly_safe_only:\n",
    "        safe_set = np.logical_xor(lyapunov.safe_set, lyapunov.initial_safe_set)\n",
    "    else:\n",
    "        safe_set = lyapunov.safe_set\n",
    "    \n",
    "    # Current safe set\n",
    "    safe_states = state_discretization.all_points[safe_set, :]      # D_n\n",
    "    \n",
    "    # Values and confidence intervals\n",
    "    tf_mean, tf_var = lyapunov.dynamics(tf_states, tf_actions)      # mu_n(x,u), diag(Sigma_n(x,u))**1/2\n",
    "    tf_mean_future_vals = lyapunov.lyapunov_function(tf_mean)       # v(mu_n(x,u))\n",
    "    tf_lv = lyapunov.lipschitz_lyapunov(tf_mean)                    # L_v(mu_n(x,u))\n",
    "    tf_bound = tf.reduce_sum(tf_var, axis=1, keep_dims=True)        # beta * sigma_n(x,u)\n",
    "    \n",
    "    if tf_lv.shape[1] == 1:\n",
    "        tf_error = tf_lv * tf_bound                                 # L_v * beta * sigma_n(x,u)\n",
    "    else:\n",
    "        tf_error = tf.reduce_sum(tf_lv * tf_var, axis=1, keep_dims=True)\n",
    "                                        \n",
    "    # Check decrease condition for stability\n",
    "    tf_upper_future_vals = tf_mean_future_vals + tf_error           # u_n(x,u)\n",
    "    tf_decrease = tf_upper_future_vals - tf_vals                    # u_n(x,u) - v(x)\n",
    "    tf_threshold = lyapunov.threshold(tf_states)                    # -L_dv * tau\n",
    "    tf_stable = tf.less(tf_decrease, tf_threshold)                  # u_n(x,u) - v(x) < -L_dv * tau\n",
    "    \n",
    "    # Check if state-action pairs map back into safe set\n",
    "    tf_maps_inside = tf.less(tf_upper_future_vals, lyapunov.c_max)  # S_n\n",
    "\n",
    "    # Update feed dict and compute\n",
    "    lyapunov.feed_dict.update({tf_states: safe_states})\n",
    "    (var, lv, bound, error, true_decrease, decrease, threshold, stable, upper_future_values, maps_inside, \n",
    "     values, future_values) = session.run(\n",
    "        [tf_var,\n",
    "         tf_lv,\n",
    "         tf_bound,\n",
    "         tf_error,\n",
    "         tf_true_decrease,\n",
    "         tf_decrease,\n",
    "         tf_threshold,\n",
    "         tf_stable,\n",
    "         tf_upper_future_vals,\n",
    "         tf_maps_inside,\n",
    "         tf_vals,\n",
    "         tf_true_future_vals],\n",
    "        lyapunov.feed_dict)\n",
    "    \n",
    "    order = np.argsort(values.ravel())\n",
    "        \n",
    "    # Use pandas frame for nice printing\n",
    "    data = OrderedDict()\n",
    "    data['v(x)'] = values[order].ravel()\n",
    "    data['v(f(x,u))'] = future_values[order].ravel()\n",
    "#     data['bound'] = bound[order].ravel()\n",
    "    data['std'] = np.around(var[order, :], decimals=5).tolist()\n",
    "    data['L_v'] = np.around(lv[order, :], decimals=2).tolist()\n",
    "    data['err/beta'] = error[order].ravel() / beta\n",
    "    data['u(x,u)'] = upper_future_values[order].ravel()\n",
    "#     data['threshold'] = threshold[order].ravel()    \n",
    "    data['stable'] = stable[order].ravel()\n",
    "#     data['maps in'] = maps_inside[order].ravel()\n",
    "        \n",
    "    if len(safe_states) == 0:\n",
    "        print('\\nNo new safe states! Try collecting more data to improve model.')\n",
    "    else:\n",
    "        total = len(values.ravel())\n",
    "        \n",
    "        max_decrease = np.max(decrease.ravel())\n",
    "        min_decrease = np.min(decrease.ravel())\n",
    "        print('\\nMax decrease: {}'.format(max_decrease))\n",
    "        print('Min decrease: {}\\n'.format(min_decrease))\n",
    "        \n",
    "        frame = pandas.DataFrame(data)\n",
    "        print(frame, '\\n')\n",
    "        \n",
    "        all_stable = np.bool(np.prod(stable))\n",
    "        num_stable = np.sum(stable)\n",
    "        print('All stable?', all_stable)\n",
    "        if not all_stable:\n",
    "            print('Unstable: {}/{}'.format(total - num_stable, total))\n",
    "            data = OrderedDict()\n",
    "            data['x'] = np.around(safe_states[np.logical_not(stable).ravel(), :], decimals=4).tolist()\n",
    "            data['decrease'] = decrease[np.logical_not(stable).ravel(), :].ravel()\n",
    "            data['threshold'] = threshold[np.logical_not(stable).ravel(), :].ravel()   \n",
    "            frame = pandas.DataFrame(data)\n",
    "            print(frame)\n",
    "        \n",
    "        all_map_inside = np.bool(np.prod(maps_inside))\n",
    "        num_map_inside = np.sum(maps_inside)\n",
    "        print('\\nAll map inside?', all_map_inside)\n",
    "        if not all_map_inside:\n",
    "            print('Map outside: {}/{}'.format(total - num_map_inside, total))\n",
    "            data = OrderedDict()\n",
    "            data['x'] = np.around(safe_states[np.logical_not(maps_inside).ravel(), :], decimals=4).tolist()\n",
    "            data['v(x)'] = values[np.logical_not(maps_inside).ravel(), :].ravel()\n",
    "            data['v(f(x,u))'] = future_values[np.logical_not(maps_inside).ravel(), :].ravel()\n",
    "            data['u_n(x,u)'] = upper_future_values[np.logical_not(maps_inside).ravel(), :].ravel()  \n",
    "            frame = pandas.DataFrame(data)\n",
    "            print(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "dt = 0.01   # sampling time\n",
    "g = 9.81    # gravity\n",
    "\n",
    "# True system parameters\n",
    "m = 0.15    # pendulum mass\n",
    "L = 0.5     # pole length\n",
    "b = 0.1     # rotational friction\n",
    "\n",
    "# State and action normalizers\n",
    "theta_max = np.deg2rad(30)\n",
    "omega_max = np.sqrt(g / L)\n",
    "u_max = g * m * L * np.sin(theta_max)\n",
    "\n",
    "state_norm = (theta_max, omega_max)\n",
    "action_norm = (u_max, )\n",
    "\n",
    "# Dimensions and domains\n",
    "state_dim = 2\n",
    "action_dim = 1\n",
    "state_limits = np.array([[-1., 1.]]*state_dim)\n",
    "action_limits = np.array([[-1., 1.]]*action_dim)\n",
    "\n",
    "# True system\n",
    "true_pendulum = InvertedPendulum(m, L, b, dt, [state_norm, action_norm])\n",
    "A_true, B_true = true_pendulum.linearize()\n",
    "\n",
    "if use_linear_dynamics:\n",
    "    true_dynamics = safe_learning.functions.LinearSystem((A_true, B_true), name='true_dynamics')\n",
    "else:\n",
    "    true_dynamics = true_pendulum.__call__\n",
    "\n",
    "# \"Wrong\" system\n",
    "m = 0.1     # pendulum mass\n",
    "L = 0.5     # pole length\n",
    "b = 0.0     # rotational friction\n",
    "pendulum = InvertedPendulum(m, L, b, dt, [state_norm, action_norm])\n",
    "A, B = pendulum.linearize()\n",
    "\n",
    "if use_true_parameters:\n",
    "    A = A_true\n",
    "    B = B_true\n",
    "mean_dynamics = safe_learning.LinearSystem((A, B), name='mean_dynamics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_true = np.hstack((A_true, B_true))\n",
    "m = np.hstack((A, B))\n",
    "variances = (m_true - m) ** 2\n",
    "\n",
    "# Make sure at least some non-zero prior variance is maintained\n",
    "np.clip(variances, 1e-3, None, out=variances)\n",
    "\n",
    "# Measurement noise\n",
    "noise_var = 0.001 ** 2\n",
    "\n",
    "# Input to GP is of the form (x,u)\n",
    "full_dim = state_dim + action_dim\n",
    "\n",
    "# Kernels\n",
    "if use_simplified_kernels:\n",
    "    kernel_theta = gpflow.kernels.Linear(full_dim, variance=variances[0, :], ARD=True)\n",
    "\n",
    "    kernel_omega = gpflow.kernels.Linear(full_dim, variance=variances[1, :], ARD=True)\n",
    "\n",
    "else:\n",
    "    kernel_theta = (gpflow.kernels.Linear(full_dim, variance=variances[0, :], ARD=True)\n",
    "                    + gpflow.kernels.Matern32(1, lengthscales=1, active_dims=[0])\n",
    "                    * gpflow.kernels.Linear(1, variance=variances[0, 1]))\n",
    "\n",
    "    kernel_omega = (gpflow.kernels.Linear(full_dim, variance=variances[1, :], ARD=True)\n",
    "                    + gpflow.kernels.Matern32(1, lengthscales=1, active_dims=[0])\n",
    "                    * gpflow.kernels.Linear(1, variance=variances[1, 1]))\n",
    "\n",
    "# Mean dynamics\n",
    "mean_function_theta = safe_learning.LinearSystem((A[[0], :], B[[0], :]), name='mean_dynamics_theta')\n",
    "mean_function_omega = safe_learning.LinearSystem((A[[1], :], B[[1], :]), name='mean_dynamics_omega')\n",
    "\n",
    "# Define a GP model over the dynamics\n",
    "# gpflow.gpr.GPR\n",
    "gp_theta = safe_learning.GPRCached(np.empty((0, full_dim), dtype=np_dtype),\n",
    "                                   np.empty((0, 1), dtype=np_dtype),\n",
    "                                   kernel_theta,\n",
    "                                   mean_function_theta)\n",
    "\n",
    "gp_omega = safe_learning.GPRCached(np.empty((0, full_dim), dtype=np_dtype),\n",
    "                                   np.empty((0, 1), dtype=np_dtype),\n",
    "                                   kernel_omega,\n",
    "                                   mean_function_omega)\n",
    "\n",
    "gp_theta.likelihood.variance = noise_var\n",
    "gp_omega.likelihood.variance = noise_var\n",
    "\n",
    "#\n",
    "gp_theta_fun = safe_learning.GaussianProcess(gp_theta, beta)\n",
    "gp_omega_fun = safe_learning.GaussianProcess(gp_omega, beta)\n",
    "\n",
    "# Stack GP functions => block-diagonal kernel matrix\n",
    "dynamics = safe_learning.FunctionStack((gp_theta_fun, gp_omega_fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of states along each dimension\n",
    "num_states = [2001, 1501]\n",
    "# num_states = [51,]*state_dim\n",
    "\n",
    "# State grid\n",
    "grid_limits = np.array([[-2., 2.], [-1.5, 1.5]])\n",
    "state_discretization = safe_learning.GridWorld(grid_limits, num_states)\n",
    "\n",
    "# Discretization constant\n",
    "if ignore_threshold:\n",
    "    tau = 0.0\n",
    "else:\n",
    "    tau = np.min(state_discretization.unit_maxes)\n",
    "\n",
    "print('Grid size: {}'.format(state_discretization.nindex))\n",
    "print('Discretization constant: {}'.format(tau))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State cost matrix\n",
    "Q = np.diag([1., 2.])\n",
    "\n",
    "# Action cost matrix\n",
    "R = 1.2*np.identity(action_dim)\n",
    "\n",
    "# Quadratic cost function\n",
    "cost_function = safe_learning.QuadraticFunction(block_diag(Q, R), name='cost_function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyapunov Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix policy to the LQR solution for the \"wrong\" system\n",
    "K, P = safe_learning.utilities.dlqr(A, B, Q, R)\n",
    "policy = safe_learning.LinearSystem(-K, name='policy')\n",
    "if saturate:\n",
    "    policy = safe_learning.Saturation(policy, -1, 1)\n",
    "\n",
    "# TensorFlow variables\n",
    "tf_states = tf.placeholder(tf_dtype, shape=[None, state_dim], name='states')\n",
    "tf_actions = policy(tf_states)\n",
    "\n",
    "# Define the Lyapunov function corresponding to the known policy\n",
    "lyapunov_function = safe_learning.QuadraticFunction(P)\n",
    "grad_lyapunov_function = safe_learning.LinearSystem((2*P,))\n",
    "\n",
    "# Lipschitz constants\n",
    "L_pol = lambda s: tf.constant(np.linalg.norm(-K, 1), dtype=tf_dtype)\n",
    "L_dyn = lambda s: np.linalg.norm(A_true, 1) + np.linalg.norm(B_true, 1)*L_pol(s)\n",
    "if use_lipschitz_scaling:\n",
    "    L_v = lambda s: tf.abs(grad_lyapunov_function(s))\n",
    "else:\n",
    "    L_v = lambda s: tf.norm(grad_lyapunov_function(s), ord=1, axis=1, keep_dims=True)\n",
    "    \n",
    "# Set initial safe set as a level set of the Lyapunov function\n",
    "values = session.run(lyapunov_function(tf_states), {tf_states: state_discretization.all_points})\n",
    "cutoff = 5e-3 * np.max(values)\n",
    "initial_safe_set = np.squeeze(values, axis=1) <= cutoff\n",
    "\n",
    "# Initialize class\n",
    "lyapunov = safe_learning.Lyapunov(state_discretization, lyapunov_function, dynamics, \n",
    "                                  L_dyn, L_v, tau, policy, initial_safe_set)\n",
    "\n",
    "# Visualize policy\n",
    "n_points = [81, 81]\n",
    "plot_policy(tf_actions, None, n_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Safe Set Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare safe set before and after checking the decrease condition for the first time\n",
    "c_max = lyapunov.feed_dict[lyapunov.c_max]\n",
    "init_safe_set_size = np.sum(lyapunov.safe_set)\n",
    "\n",
    "print('Before update ...')\n",
    "print('c_max: {}'.format(c_max))\n",
    "print('Safe set size: {}\\n'.format(init_safe_set_size))\n",
    "\n",
    "old_safe_set = np.copy(lyapunov.safe_set)\n",
    "lyapunov.update_safe_set()\n",
    "\n",
    "c_max = lyapunov.feed_dict[lyapunov.c_max]\n",
    "init_safe_set_size = np.sum(lyapunov.safe_set)\n",
    "\n",
    "print('After update ...')\n",
    "print('c_max: {}'.format(c_max))\n",
    "print('Safe set size: {}'.format(init_safe_set_size))\n",
    "\n",
    "plot_safe_set(lyapunov, old_safe_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Learning and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action_variation = np.array([-0.02, 0.0, 0.02], dtype=np_dtype).reshape((-1, 1))\n",
    "action_variation = np.array([-0.01, -0.001, 0.0, 0.001, 0.01], dtype=np_dtype).reshape((-1, 1))\n",
    "# action_variation = np.array([[0.]], dtype=np_dtype)\n",
    "\n",
    "with tf.name_scope('add_new_measurement'):\n",
    "    full_dim = state_dim + action_dim \n",
    "    tf_max_state_action = tf.placeholder(tf_dtype, shape=[1, full_dim])\n",
    "    tf_measurement = true_dynamics(tf_max_state_action)\n",
    "    \n",
    "def update_gp():\n",
    "    \"\"\"Update the GP model based on an actively selected data point.\"\"\"\n",
    "    \n",
    "    # Get a new sample location\n",
    "    max_state_action, _ = safe_learning.get_safe_sample(lyapunov,\n",
    "                                                        action_variation,\n",
    "                                                        action_limits,\n",
    "                                                        positive=True,\n",
    "                                                        num_samples=1000)\n",
    "    \n",
    "    # Obtain a measurement of the true dynamics\n",
    "    lyapunov.feed_dict[tf_max_state_action] = max_state_action\n",
    "    measurement = tf_measurement.eval(feed_dict=lyapunov.feed_dict)\n",
    "    \n",
    "    # Add the measurement to our GP dynamics\n",
    "    lyapunov.dynamics.add_data_point(max_state_action, measurement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_update = 10\n",
    "safe_set_updates = 1\n",
    "\n",
    "\n",
    "for i in range(safe_set_updates):\n",
    "    \n",
    "#     print('Iteration {} with c_max: {}'.format(i, lyapunov.feed_dict[lyapunov.c_max]))\n",
    "    old_safe_set = np.copy(lyapunov.safe_set)\n",
    "\n",
    "    for _ in tqdm(range(data_per_update)):\n",
    "        update_gp()\n",
    "\n",
    "    lyapunov.update_safe_set()\n",
    "    plot_safe_set(lyapunov, old_safe_set)\n",
    "\n",
    "\n",
    "current_safe_set_size = np.sum(lyapunov.safe_set)\n",
    "print('Safe set size: {}'.format(current_safe_set_size))\n",
    "print('Growth: {}'.format(current_safe_set_size - init_safe_set_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accepted \"safe\" state-action pairs\n",
    "data = lyapunov.dynamics.functions[0].X\n",
    "print(\"Data points collected: {}\\n\".format(data.shape[0]))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(gp_theta.predict_f(data[0,:].reshape(1, -1)))\n",
    "# print(gp_theta.likelihood.variance.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
