{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability Verification for a Cart-Pole System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "from scipy.linalg import block_diag\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "import safe_learning\n",
    "from utilities import CartPole, debug, visuals\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    tqdm = lambda x: x\n",
    "    \n",
    "np_dtype = safe_learning.config.np_dtype\n",
    "tf_dtype = safe_learning.config.dtype\n",
    "\n",
    "try:\n",
    "    session.close()\n",
    "except NameError:\n",
    "    pass\n",
    "session = tf.InteractiveSession()\n",
    "\n",
    "# TODO debug flags ***************************************#\n",
    "\n",
    "import pandas\n",
    "pandas.options.display.float_format = '{:,.4f}'.format\n",
    "pandas.set_option('expand_frame_repr', False)\n",
    "np.set_printoptions(precision=4)\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "# Saturate the action so that it lies in [-1, 1]\n",
    "SATURATE = True\n",
    "\n",
    "# Use the true physical parameters in the GP model\n",
    "USE_TRUE_PARAMETERS = True\n",
    "\n",
    "# Use the linearized discrete-time model as the true underlying dynamics\n",
    "USE_LINEAR_DYNAMICS = True\n",
    "\n",
    "# Use a threshold of zero when checking for stability\n",
    "USE_ZERO_THRESHOLD = True\n",
    "\n",
    "#\n",
    "USE_LINEAR_KERNELS = True\n",
    "\n",
    "#\n",
    "USE_LIPSCHITZ_SCALING = True\n",
    "\n",
    "# Scaling factor for GP confidence intervals\n",
    "BETA = 2.\n",
    "\n",
    "#\n",
    "TRAIN_HYPERPARAMETERS = False\n",
    "\n",
    "#\n",
    "GP_SCALING = 1e3\n",
    "\n",
    "#\n",
    "NOISE_VAR = 0.0001 ** 2\n",
    "\n",
    "#******************************************************#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "dt = 0.01   # sampling time\n",
    "g = 9.81    # gravity\n",
    "\n",
    "# m = 0.1\n",
    "# M = 1.5\n",
    "# L = 0.5\n",
    "# b = 0.0\n",
    "# x_max = 0.25\n",
    "# theta_max = np.deg2rad(20)\n",
    "# v_max = 0.5\n",
    "# omega_max = np.deg2rad(10)\n",
    "# u_max = (m + M)*v_max / (5*dt)\n",
    "\n",
    "# True system parameters\n",
    "m = 0.175    # pendulum mass\n",
    "M = 1.732    # cart mass\n",
    "L = 0.28     # pole length\n",
    "b = 0.0      # rotational friction\n",
    "\n",
    "# State and action normalizers\n",
    "x_max = 0.5\n",
    "theta_max = np.deg2rad(30)\n",
    "v_max = 1. # 5.\n",
    "omega_max = 0.25*np.sqrt(g / L)\n",
    "u_max = 190\n",
    "\n",
    "state_norm = (x_max, theta_max, v_max, omega_max)\n",
    "action_norm = (u_max, )\n",
    "\n",
    "# Constraints for initial 'safe' states\n",
    "x_safe = x_max\n",
    "theta_safe = np.deg2rad(8)\n",
    "v_safe = 0.1\n",
    "omega_safe = np.deg2rad(6)\n",
    "\n",
    "# Dimensions and domains\n",
    "state_dim = 4\n",
    "action_dim = 1\n",
    "state_limits = np.array([[-1., 1.]]*state_dim)\n",
    "action_limits = np.array([[-1., 1.]]*action_dim)\n",
    "\n",
    "# True system\n",
    "true_cartpole = CartPole(m, M, L, b, dt, [state_norm, action_norm])\n",
    "A_true, B_true = true_cartpole.linearize()\n",
    "\n",
    "if USE_LINEAR_DYNAMICS:\n",
    "    true_dynamics = safe_learning.functions.LinearSystem((A_true, B_true), name='true_dynamics')\n",
    "else:\n",
    "    true_dynamics = true_cartpole.__call__\n",
    "\n",
    "# \"Wrong\" system\n",
    "m = 0.2     # pendulum mass\n",
    "M = 1.5     # cart mass\n",
    "L = 0.25    # pole length\n",
    "b = 0.0     # rotational friction\n",
    "cartpole = CartPole(m, M, L, b, dt, [state_norm, action_norm])\n",
    "A, B = cartpole.linearize()\n",
    "\n",
    "if USE_TRUE_PARAMETERS:\n",
    "    A = A_true\n",
    "    B = B_true\n",
    "mean_dynamics = safe_learning.LinearSystem((A, B), name='mean_dynamics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_norm)\n",
    "print(action_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m_true = np.hstack((A_true, B_true))\n",
    "m = np.hstack((A, B))\n",
    "variances = (m_true - m) ** 2\n",
    "\n",
    "# Make sure at least some non-zero prior variance is maintained\n",
    "np.clip(variances, 1e-3, None, out=variances)\n",
    "\n",
    "# Measurement noise\n",
    "noise_var = NOISE_VAR\n",
    "\n",
    "# Input to GP is of the form (x,u)\n",
    "full_dim = state_dim + action_dim\n",
    "\n",
    "# Kernels\n",
    "if USE_LINEAR_KERNELS:\n",
    "    kernel_x = gpflow.kernels.Linear(full_dim, variance=variances[0, :], ARD=True)\n",
    "    \n",
    "    kernel_theta = gpflow.kernels.Linear(full_dim, variance=variances[1, :], ARD=True)\n",
    "\n",
    "    kernel_v = gpflow.kernels.Linear(full_dim, variance=variances[2, :], ARD=True)\n",
    "\n",
    "    kernel_omega = gpflow.kernels.Linear(full_dim, variance=variances[3, :], ARD=True)\n",
    "\n",
    "else:\n",
    "    kernel_x = (gpflow.kernels.Linear(full_dim, variance=variances[0, :], ARD=True)\n",
    "                + (  gpflow.kernels.Linear(1, variance=variances[0, 1], active_dims=[1])                   # theta\n",
    "                   + gpflow.kernels.Matern32(1, variance=variances[0, 3], lengthscales=1, active_dims=[3]) # omega\n",
    "                   + gpflow.kernels.Linear(1, variance=variances[0, 4], active_dims=[4])                   # u\n",
    "                 ) * gpflow.kernels.Matern32(1, lengthscales=1, active_dims=[1]) \n",
    "    )\n",
    "\n",
    "    kernel_theta = (gpflow.kernels.Linear(full_dim, variance=variances[1, :], ARD=True)\n",
    "                    + (  gpflow.kernels.Linear(1, variance=variances[1, 1], active_dims=[1])                   # theta\n",
    "                       + gpflow.kernels.Matern32(1, variance=variances[1, 3], lengthscales=1, active_dims=[3]) # omega\n",
    "                       + gpflow.kernels.Linear(1, variance=variances[1, 4], active_dims=[4])                   # u\n",
    "                     ) * gpflow.kernels.Matern32(1, lengthscales=1, active_dims=[1])\n",
    "    )\n",
    "\n",
    "    kernel_v = (gpflow.kernels.Linear(full_dim, variance=variances[2, :], ARD=True) \n",
    "                + (  gpflow.kernels.Linear(1, variance=variances[2, 1], active_dims=[1])                   # theta\n",
    "                   + gpflow.kernels.Matern32(1, variance=variances[2, 3], lengthscales=1, active_dims=[3]) # omega\n",
    "                   + gpflow.kernels.Linear(1, variance=variances[2, 4], active_dims=[4])                   # u\n",
    "                 ) * gpflow.kernels.Matern32(1, lengthscales=1, active_dims=[1]) \n",
    "    )\n",
    "\n",
    "    kernel_omega = (gpflow.kernels.Linear(full_dim, variance=variances[3, :], ARD=True)\n",
    "                    + (  gpflow.kernels.Linear(1, variance=variances[3, 1], active_dims=[1])                   # theta\n",
    "                       + gpflow.kernels.Matern32(1, variance=variances[3, 3], lengthscales=1, active_dims=[3]) # omega\n",
    "                       + gpflow.kernels.Linear(1, variance=variances[3, 4], active_dims=[4])                   # u\n",
    "                     ) * gpflow.kernels.Matern32(1, lengthscales=1, active_dims=[1])\n",
    "    )\n",
    "\n",
    "# Mean dynamics\n",
    "mean_function_x = safe_learning.LinearSystem((A[[0], :], B[[0], :]), name='mean_dynamics_x')\n",
    "mean_function_theta = safe_learning.LinearSystem((A[[1], :], B[[1], :]), name='mean_dynamics_theta')\n",
    "mean_function_v = safe_learning.LinearSystem((A[[2], :], B[[2], :]), name='mean_dynamics_v')\n",
    "mean_function_omega = safe_learning.LinearSystem((A[[3], :], B[[3], :]), name='mean_dynamics_omega')\n",
    "\n",
    "# Define a GP model over the dynamics\n",
    "gp_x = safe_learning.GPRCached(np.empty((0, full_dim), dtype=np_dtype),    # collected input data, X\n",
    "                               np.empty((0, 1), dtype=np_dtype),           # collected output data, Y\n",
    "                               kernel_x,                                   # kernel function, k(x,x')\n",
    "                               mean_function_x,                            # mean function, mu(x)\n",
    "                               scaling=GP_SCALING)\n",
    "\n",
    "gp_theta = safe_learning.GPRCached(np.empty((0, full_dim), dtype=np_dtype), \n",
    "                                   np.empty((0, 1), dtype=np_dtype),\n",
    "                                   kernel_theta, \n",
    "                                   mean_function_theta,\n",
    "                                   scaling=GP_SCALING)\n",
    "\n",
    "gp_v = safe_learning.GPRCached(np.empty((0, full_dim), dtype=np_dtype), \n",
    "                               np.empty((0, 1), dtype=np_dtype),\n",
    "                               kernel_v, \n",
    "                               mean_function_v,\n",
    "                               scaling=GP_SCALING)\n",
    "\n",
    "gp_omega = safe_learning.GPRCached(np.empty((0, full_dim), dtype=np_dtype), \n",
    "                                   np.empty((0, 1), dtype=np_dtype),\n",
    "                                   kernel_omega, \n",
    "                                   mean_function_omega,\n",
    "                                   scaling=GP_SCALING)\n",
    "\n",
    "gp_x.likelihood.variance = noise_var\n",
    "gp_theta.likelihood.variance = noise_var\n",
    "gp_v.likelihood.variance = noise_var\n",
    "gp_omega.likelihood.variance = noise_var\n",
    "\n",
    "if TRAIN_HYPERPARAMETERS:\n",
    "    # Sample state-actions (x, u) and observations from the dynamics\n",
    "    N = 1e3\n",
    "    states = sample_box(state_limits, N)\n",
    "    actions = sample_box(action_limits, N)\n",
    "    X = np.concatenate((states, actions), axis=1)\n",
    "    Y = true_dynamics(states, actions).eval()\n",
    "\n",
    "    for i, gp in (gp_x, gp_theta, gp_v, gp_omega):\n",
    "\n",
    "        # \n",
    "        print('Original parameters:', gp, '\\n')\n",
    "\n",
    "        # Optimize the parameters of each GP via MLE\n",
    "        print('Optimizing ...\\n')\n",
    "        gp.X = X\n",
    "        gp.Y = Y[:, i].reshape((-1, 1))\n",
    "        gp.optimize()\n",
    "\n",
    "        # Reset GP data matrices for safe learning\n",
    "        gp.X = np.empty((0, full_dim), dtype=np_dtype)\n",
    "        gp.Y = np.empty((0, 1), dtype=np_dtype)\n",
    "        gp.update_cache()\n",
    "\n",
    "        # \n",
    "        print('New parameters:', gp, '\\n')\n",
    "\n",
    "gp_x_fun = safe_learning.GaussianProcess(gp_x, BETA)\n",
    "gp_theta_fun = safe_learning.GaussianProcess(gp_theta, BETA)\n",
    "gp_v_fun = safe_learning.GaussianProcess(gp_v, BETA)\n",
    "gp_omega_fun = safe_learning.GaussianProcess(gp_omega, BETA)\n",
    "\n",
    "# Stack GP functions => block-diagonal kernel matrix\n",
    "dynamics = safe_learning.FunctionStack((gp_x_fun, gp_theta_fun, gp_v_fun, gp_omega_fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of states along each dimension\n",
    "num_states = [51, ]*state_dim\n",
    "\n",
    "# State grid\n",
    "grid_limits = np.array([[-1., 1.], [-1., 1.], [-1., 1.], [-1., 1.]])\n",
    "state_discretization = safe_learning.GridWorld(grid_limits, num_states)\n",
    "\n",
    "# Discretization constant\n",
    "if USE_ZERO_THRESHOLD:\n",
    "    tau = 0.0\n",
    "else:\n",
    "    tau = np.min(state_discretization.unit_maxes)\n",
    "\n",
    "print('Grid size: {}'.format(state_discretization.nindex))\n",
    "print('Discretization constant: {}'.format(tau))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# State cost matrix\n",
    "Q = np.diag([0.1, 0.1, 1., 1.]).astype(np_dtype)\n",
    "\n",
    "# Action cost matrix\n",
    "R = np.identity(action_dim).astype(np_dtype)\n",
    "\n",
    "# Normalize cost matrices\n",
    "cost_norm = np.max([Q.max(), R.max()])\n",
    "Q = Q / cost_norm\n",
    "R = R / cost_norm\n",
    "\n",
    "# Quadratic cost function\n",
    "cost_function = safe_learning.QuadraticFunction(block_diag(Q, R), name='cost_function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyapunov Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fix policy to the LQR solution for the \"wrong\" system\n",
    "# K, P = safe_learning.utilities.dlqr(A, B, Q, R)\n",
    "K, P = safe_learning.utilities.dlqr(A_true, B_true, Q, R)\n",
    "policy = safe_learning.LinearSystem(-K, name='policy')\n",
    "\n",
    "if SATURATE:\n",
    "    policy = safe_learning.Saturation(policy, -1, 1)\n",
    "    \n",
    "# TensorFlow variables\n",
    "tf_states = tf.placeholder(tf_dtype, shape=[None, state_dim], name='states')\n",
    "tf_actions = policy(tf_states)\n",
    "\n",
    "# Define the Lyapunov function corresponding to the known policy\n",
    "lyapunov_function = safe_learning.QuadraticFunction(P)\n",
    "grad_lyapunov_function = safe_learning.LinearSystem((2*P,))\n",
    "\n",
    "# Lipschitz constants\n",
    "L_pol = lambda s: tf.constant(np.linalg.norm(-K, 1), dtype=tf_dtype)\n",
    "L_dyn = lambda s: np.linalg.norm(A_true, 1) + np.linalg.norm(B_true, 1)*L_pol(s)\n",
    "\n",
    "if USE_LIPSCHITZ_SCALING:\n",
    "    L_v = lambda s: tf.abs(grad_lyapunov_function(s))\n",
    "else:\n",
    "    L_v = lambda s: tf.norm(grad_lyapunov_function(s), ord=1, axis=1, keep_dims=True)\n",
    "\n",
    "# val_func = lambda X: np.sum(X.dot(P) * X, axis=1, keepdims=True)\n",
    "# np_func = lambda s: approx_local_lipschitz_grid(val_func, s, tau, 1e3)\n",
    "# L_v = lambda s: tf.py_func(np_func, [s], tf_dtype, name='approx_lipschitz')\n",
    "    \n",
    "# Set initial safe set as a level set of the Lyapunov function\n",
    "# values = session.run(lyapunov_function(tf_states), {tf_states: state_discretization.all_points})\n",
    "# cutoff = 3e-3 * np.max(values)\n",
    "# initial_safe_set = np.squeeze(values, axis=1) <= cutoff\n",
    "\n",
    "# Set initial safe set as a hypercube in the state space\n",
    "# safe_norm = np.array([[x_safe / x_max, theta_safe / theta_max, v_safe / v_max, omega_safe / omega_max]])\n",
    "safe_norm = np.array([[0.75, 0.5, 0.2, 0.25]])\n",
    "norm_states = state_discretization.all_points / safe_norm\n",
    "initial_safe_set = np.all(np.logical_and(norm_states >= -1, norm_states <= 1), axis=1, keepdims=False)\n",
    "\n",
    "# Initialize class\n",
    "lyapunov = safe_learning.Lyapunov(state_discretization, lyapunov_function, dynamics, \n",
    "                                  L_dyn, L_v, tau, policy, initial_safe_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_policy(lyapunov, tf_states, fixed_state, state_norm=None):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5), dpi=100)\n",
    "    fig.subplots_adjust(wspace=0.4, hspace=0.2)\n",
    "    cmap = plt.get_cmap('viridis')\n",
    "    cmap.set_under('indigo')\n",
    "    cmap.set_over('gold')\n",
    "    ticks = np.linspace(-1., 1., 9)\n",
    "    cutoff = 1. - 1e-5\n",
    "    \n",
    "    fixed_state = np.asarray(fixed_state, dtype=np_dtype)\n",
    "    for i in range(4):\n",
    "        dist = np.square(lyapunov.discretization.discrete_points[i] - fixed_state[i])\n",
    "        idx = np.argmin(dist)\n",
    "        fixed_state[i] = lyapunov.discretization.discrete_points[i][idx]\n",
    "    x_fix, theta_fix, v_fix, omega_fix = fixed_state\n",
    "    pos_set = np.logical_and(lyapunov.discretization.all_points[:, 1] == theta_fix, \n",
    "                             lyapunov.discretization.all_points[:, 3] == omega_fix)\n",
    "    vel_set = np.logical_and(lyapunov.discretization.all_points[:, 0] == x_fix,\n",
    "                             lyapunov.discretization.all_points[:, 2] == v_fix)\n",
    "    \n",
    "    if state_norm is not None:\n",
    "        x_max, theta_max, v_max, omega_max = state_norm\n",
    "        scale = np.array([x_max, np.rad2deg(theta_max), \n",
    "                          v_max, np.rad2deg(omega_max)]).reshape((-1, 1))\n",
    "        limits = scale * lyapunov.discretization.limits\n",
    "        x_fix, theta_fix, v_fix, omega_fix = fixed_state * scale.ravel()\n",
    "    else:\n",
    "        limits = lyapunov.discretization.limits\n",
    "    \n",
    "    # Fix v and omega, plot policy over x and theta\n",
    "    grid = lyapunov.discretization.all_points[pos_set, :]\n",
    "    z = session.run(lyapunov.policy(tf_states), feed_dict={tf_states: grid})\n",
    "    z = z.reshape(lyapunov.discretization.num_points[:2])\n",
    "    im = ax[0].imshow(z.T, \n",
    "                      origin='lower', \n",
    "                      extent=limits[(0, 2), :].ravel(), \n",
    "                      aspect=limits[0, 0] / limits[2, 0],\n",
    "                      cmap=cmap,\n",
    "                      vmin=-cutoff,\n",
    "                      vmax=cutoff)\n",
    "    cbar = fig.colorbar(im, ax=ax[0], label=r'$u = \\pi(x)$', ticks=ticks)\n",
    "    ax[0].set_title(r'$\\theta = %.3g$ deg, $\\omega = %.3g$ deg/s' % (theta_fix, omega_fix))\n",
    "    ax[0].set_xlabel(r'$x$ [m]')\n",
    "    ax[0].set_ylabel(r'$v$ [m/s]')\n",
    "  \n",
    "    # Fix x and theta, plot policy over v and omega\n",
    "    grid = lyapunov.discretization.all_points[vel_set, :]\n",
    "    z = session.run(lyapunov.policy(tf_states), feed_dict={tf_states: grid})\n",
    "    z = z.reshape(lyapunov.discretization.num_points[2:])\n",
    "    im = ax[1].imshow(z.T, \n",
    "                      origin='lower', \n",
    "                      extent=limits[(1, 3), :].ravel(), \n",
    "                      aspect=limits[1, 0] / limits[3, 0],\n",
    "                      cmap=cmap,\n",
    "                      vmin=-cutoff,\n",
    "                      vmax=cutoff)\n",
    "    cbar = fig.colorbar(im, ax=ax[1], label=r'$u = \\pi(x)$', ticks=ticks)\n",
    "    ax[1].set_title(r'$x = %.3g$ m, $v = %.3g$ deg' % (x_fix, v_fix))\n",
    "    ax[1].set_xlabel(r'$\\theta$ [deg]')\n",
    "    ax[1].set_ylabel(r'$\\omega$ [deg/s]')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Visualize policy\n",
    "fixed_state = [0., 0., 0., 0.]\n",
    "plot_policy(lyapunov, tf_states, fixed_state, state_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Safe Set Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare safe set before and after checking the decrease condition for the first time\n",
    "c_max = lyapunov.feed_dict[lyapunov.c_max]\n",
    "init_safe_set_size = np.sum(lyapunov.safe_set)\n",
    "\n",
    "print('Before update ...')\n",
    "print('c_max: {}'.format(c_max))\n",
    "print('Safe set size: {}\\n'.format(init_safe_set_size))\n",
    "\n",
    "old_safe_set = np.copy(lyapunov.safe_set)\n",
    "lyapunov.update_safe_set()\n",
    "\n",
    "c_max = lyapunov.feed_dict[lyapunov.c_max]\n",
    "init_safe_set_size = np.sum(lyapunov.safe_set)\n",
    "\n",
    "print('After update ...')\n",
    "print('c_max: {}'.format(c_max))\n",
    "print('Safe set size: {}'.format(init_safe_set_size))\n",
    "\n",
    "visuals(lyapunov, tf_states, state_norm, plot='cartpole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "debug(lyapunov, true_dynamics, tf_states, newly_safe_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Learning and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# action_variation = np.array([-0.1, -0.01, -0.001, 0., 0.001, 0.01, 0.1], \n",
    "#                             dtype=np_dtype).reshape((-1, 1))\n",
    "\n",
    "action_variation = np.array([0.], dtype=np_dtype).reshape((-1, 1))\n",
    "\n",
    "with tf.name_scope('add_new_measurement'):\n",
    "    full_dim = state_dim + action_dim \n",
    "    tf_max_state_action = tf.placeholder(tf_dtype, shape=[1, full_dim])\n",
    "    tf_measurement = true_dynamics(tf_max_state_action)\n",
    "    \n",
    "def update_gp():\n",
    "    \"\"\"Update the GP model based on an actively selected data point.\"\"\"\n",
    "    \n",
    "    # Get a new sample location\n",
    "    max_state_action, _ = safe_learning.get_safe_sample(lyapunov,\n",
    "                                                        action_variation,\n",
    "                                                        action_limits,\n",
    "                                                        positive=True,\n",
    "                                                        num_samples=1000)\n",
    "    \n",
    "    # Obtain a measurement of the true dynamics\n",
    "    lyapunov.feed_dict[tf_max_state_action] = max_state_action\n",
    "    measurement = tf_measurement.eval(feed_dict=lyapunov.feed_dict)\n",
    "    \n",
    "    # Add the measurement to our GP dynamics\n",
    "    lyapunov.dynamics.add_data_point(max_state_action, measurement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_per_update = 10\n",
    "safe_set_updates = 1\n",
    "\n",
    "# 60 to 80 data points\n",
    "\n",
    "if 'level' not in globals():\n",
    "    level = np.zeros(safe_set_updates + 1)\n",
    "    safe_size = np.zeros(safe_set_updates + 1)\n",
    "    level[0] = lyapunov.feed_dict[lyapunov.c_max]\n",
    "    safe_size[0] = np.sum(lyapunov.safe_set)\n",
    "    num_data = data_per_update*np.arange(safe_set_updates + 1)\n",
    "    e = 0\n",
    "else:\n",
    "    e = len(level) - 1\n",
    "    level = np.concatenate((level, np.zeros(safe_set_updates)))\n",
    "    safe_size = np.concatenate((safe_size, np.zeros(safe_set_updates)))\n",
    "    temp = data_per_update*np.arange(1, safe_set_updates + 1) + num_data[-1]\n",
    "    num_data = np.concatenate((num_data, temp))\n",
    "\n",
    "for i in range(safe_set_updates):\n",
    "    \n",
    "    print('Iteration {} with c_max: {}'.format(e + i + 1, lyapunov.feed_dict[lyapunov.c_max]))\n",
    "    old_safe_set = np.copy(lyapunov.safe_set)\n",
    "\n",
    "    for _ in range(data_per_update):\n",
    "#     for _ in tqdm(range(data_per_update)):\n",
    "        update_gp()\n",
    "\n",
    "    lyapunov.update_safe_set()\n",
    "    level[e + i + 1] = lyapunov.feed_dict[lyapunov.c_max]\n",
    "    safe_size[e + i + 1] = np.sum(lyapunov.safe_set)\n",
    "    \n",
    "    current_safe_set_size = np.sum(lyapunov.safe_set)\n",
    "    data = lyapunov.dynamics.functions[0].X\n",
    "    print('Discretization size: {}'.format(state_discretization.all_points.shape[0]))\n",
    "    print('Safe set size: {}'.format(current_safe_set_size))\n",
    "    print('Growth: {}'.format(current_safe_set_size - init_safe_set_size))\n",
    "    print(\"Data points collected: {}\".format(data.shape[0]))\n",
    "    print(\"New c_max: {}\".format(lyapunov.feed_dict[lyapunov.c_max]))\n",
    "    \n",
    "    fixed_state=(0., 0., 0., 0.)\n",
    "    visuals(lyapunov, tf_states, state_norm, plot='cartpole', fixed_state=fixed_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = np.argmax(num_data > 200)\n",
    "idx = 0\n",
    "if idx == 0:\n",
    "    idx = len(num_data)\n",
    "print(level, '\\n')\n",
    "print(safe_size)\n",
    "    \n",
    "fig, ax = plt.subplots(1, 2, sharex=False, figsize=(10, 3), dpi=200)\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.2)\n",
    "\n",
    "ax[0].step(num_data[:idx], level[:idx], 'o--', where='post')\n",
    "ax[0].set_xlabel(r'Number of data points collected', fontsize=12)\n",
    "ax[0].set_ylabel(r'$c_{max}$', fontsize=12)\n",
    "\n",
    "ax[1].step(num_data[:idx], safe_size[:idx], 'o--', where='post')\n",
    "ax[1].set_xlabel(r'Number of data points collected', fontsize=12)\n",
    "ax[1].set_ylabel(r'Safe set size', fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)\n",
    "states = lyapunov.dynamics.functions[0].X[:, :4]\n",
    "# scale = np.array([x_max, np.rad2deg(theta_max), v_max, np.rad2deg(omega_max)]).ravel()\n",
    "# print(scale * states)\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fixed_state = states[0, :]\n",
    "fixed_state = (0.5, 0., 0.5, 0.)\n",
    "visuals(lyapunov, tf_states, state_norm, plot='cartpole', fixed_state=fixed_state)\n",
    "\n",
    "# X = data\n",
    "# print(lyapunov.dynamics.functions[0].gaussian_process.predict_f(X))\n",
    "# print(gp_x.likelihood.variance.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
