{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability Verification for a Cart-Pole System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "from scipy.linalg import block_diag\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "import safe_learning\n",
    "from utilities import sample_box, compute_closedloop_response, CartPole, get_max_parameter_change\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    tqdm = lambda x: x\n",
    "    \n",
    "np_dtype = safe_learning.config.np_dtype\n",
    "tf_dtype = safe_learning.config.dtype\n",
    "\n",
    "try:\n",
    "    session.close()\n",
    "except NameError:\n",
    "    pass\n",
    "session = tf.InteractiveSession()\n",
    "initialized = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System parameters\n",
    "m = 0.1     # pendulum mass\n",
    "M = 0.5     # cart mass\n",
    "L = 0.3     # pole length\n",
    "\n",
    "# Constants\n",
    "dt = 0.01   # sampling time\n",
    "g = 9.81    # gravity\n",
    "\n",
    "# State and action normalizers\n",
    "x_max = 5.\n",
    "theta_max = np.deg2rad(20)\n",
    "x_dot_max = 2.\n",
    "theta_dot_max = np.deg2rad(5)\n",
    "u_max = (m + M)*x_dot_max / (10*dt)\n",
    "\n",
    "state_norm = (x_max, theta_max, x_dot_max, theta_dot_max)\n",
    "action_norm = (u_max,)\n",
    "\n",
    "# Define true system and dynamics\n",
    "true_cart_pole = CartPole(m, M, L, dt, [state_norm, action_norm])\n",
    "A_true, B_true = true_cart_pole.linearize()\n",
    "true_dynamics = safe_learning.LinearSystem((A_true, B_true), name='true_dynamics')\n",
    "\n",
    "# \"Wrong\" system\n",
    "m = 0.2     # pendulum mass\n",
    "M = 0.8     # cart mass\n",
    "L = 0.25    # pole length\n",
    "cart_pole = CartPole(m, M, L, dt, [state_norm, action_norm])\n",
    "A, B = true_cart_pole.linearize()\n",
    "mean_dynamics = safe_learning.LinearSystem((A, B), name='mean_dynamics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State cost matrix\n",
    "Q = np.diag([1., 1., 1., 1.])\n",
    "\n",
    "# Action cost matrix\n",
    "R = np.identity(cart_pole.action_dim)\n",
    "\n",
    "# Quadratic reward (-cost) function\n",
    "reward_function = safe_learning.QuadraticFunction(block_diag(-Q, -R), name='reward_function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_limits = np.array([[-1., 1.]]*cart_pole.state_dim)\n",
    "action_limits = np.array([[-1., 1.]]*cart_pole.action_dim)\n",
    "\n",
    "num_states = [51,]*cart_pole.state_dim\n",
    "state_discretization = safe_learning.GridWorld(state_limits, num_states)\n",
    "\n",
    "# Discretization constant\n",
    "tau = np.min(state_discretization.unit_maxes)\n",
    "\n",
    "print('Grid size: {}'.format(state_discretization.nindex))\n",
    "print('Discretization constant: {}'.format(tau))\n",
    "\n",
    "# tau = 0.002 for inverted pendulum!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_true = np.hstack((A_true, B_true))\n",
    "m = np.hstack((A, B))\n",
    "variances = (m_true - m) ** 2\n",
    "\n",
    "# Make sure at least some non-zero prior variance is maintained\n",
    "np.clip(variances, 1e-3, None, out=variances)\n",
    "\n",
    "noise_var = 0.001 ** 2\n",
    "full_dim = cart_pole.state_dim + cart_pole.action_dim\n",
    "\n",
    "# Kernels\n",
    "# TODO choose variances\n",
    "# TODO add non-linearities to x and theta kernels?\n",
    "kernel_x = gpflow.kernels.Linear(full_dim, variance=variances[0, :], ARD=True)\n",
    "\n",
    "kernel_theta = gpflow.kernels.Linear(full_dim, variance=variances[1, :], ARD=True)\n",
    "\n",
    "kernel_x_dot = ( gpflow.kernels.Linear(full_dim, variance=variances[2, :], ARD=True) \n",
    "                 + (  gpflow.kernels.Linear(1, variance=variances[2, 1], active_dims=[1])               # theta\n",
    "                    + gpflow.kernels.Polynomial(1, degree=2, variance=variances[2, 3], active_dims=[3]) # theta_dot\n",
    "                    + gpflow.kernels.Linear(1, variance=variances[2, 4], active_dims=[4])               # u\n",
    "                 )*gpflow.kernels.Matern32(1, lengthscales=1, active_dims=[1]) \n",
    ")\n",
    "\n",
    "kernel_theta_dot = ( gpflow.kernels.Linear(full_dim, variance=variances[3, :], ARD=True)\n",
    "                     + (  gpflow.kernels.Linear(1, variance=variances[3, 1], active_dims=[1])               # theta\n",
    "                        + gpflow.kernels.Polynomial(1, degree=2, variance=variances[3, 3], active_dims=[3]) # theta_dot\n",
    "                        + gpflow.kernels.Linear(1, variance=variances[3, 4], active_dims=[4])               # u\n",
    "                 )*gpflow.kernels.Matern32(1, lengthscales=1, active_dims=[1])\n",
    ")\n",
    "\n",
    "# Mean dynamics\n",
    "mean_function_x = safe_learning.LinearSystem((A[[0], :], B[[0], :]), name='mean_dynamics_x')\n",
    "mean_function_theta = safe_learning.LinearSystem((A[[1], :], B[[1], :]), name='mean_dynamics_theta')\n",
    "mean_function_x_dot = safe_learning.LinearSystem((A[[2], :], B[[2], :]), name='mean_dynamics_x_dot')\n",
    "mean_function_theta_dot = safe_learning.LinearSystem((A[[3], :], B[[3], :]), name='mean_dynamics_theta_dot')\n",
    "\n",
    "# Define a GP model over the dynamics\n",
    "gp_x = safe_learning.GPRCached(np.empty((0, full_dim), dtype=np_dtype), np.empty((0, 1), dtype=np_dtype),\n",
    "                               kernel_x, mean_function=mean_function_x)\n",
    "\n",
    "gp_theta = safe_learning.GPRCached(np.empty((0, full_dim), dtype=np_dtype), np.empty((0, 1), dtype=np_dtype),\n",
    "                                   kernel_theta, mean_function=mean_function_theta)\n",
    "\n",
    "gp_x_dot = safe_learning.GPRCached(np.empty((0, full_dim), dtype=np_dtype), np.empty((0, 1), dtype=np_dtype),\n",
    "                                   kernel_x_dot, mean_function=mean_function_x_dot)\n",
    "\n",
    "gp_theta_dot = safe_learning.GPRCached(np.empty((0, full_dim), dtype=np_dtype), np.empty((0, 1), dtype=np_dtype),\n",
    "                                       kernel_theta_dot, mean_function=mean_function_theta_dot)\n",
    "\n",
    "gp_x.likelihood.variance = noise_var\n",
    "gp_theta.likelihood.variance = noise_var\n",
    "gp_x_dot.likelihood.variance = noise_var\n",
    "gp_theta_dot.likelihood.variance = noise_var\n",
    "\n",
    "# TODO how to compute beta?\n",
    "beta = 2.\n",
    "gp_x_fun = safe_learning.GaussianProcess(gp_x, beta)\n",
    "gp_theta_fun = safe_learning.GaussianProcess(gp_theta, beta)\n",
    "gp_x_dot_fun = safe_learning.GaussianProcess(gp_x_dot, beta)\n",
    "gp_theta_dot_fun = safe_learning.GaussianProcess(gp_theta_dot, beta)\n",
    "\n",
    "# Stack GP functions => block-diagonal kernel matrix\n",
    "dynamics = safe_learning.FunctionStack((gp_x_fun, gp_theta_fun, gp_x_dot_fun, gp_theta_dot_fun))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyapunov Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix policy to the LQR solution for the \"wrong\" system\n",
    "K, P = safe_learning.utilities.dlqr(A_true, B_true, Q, R)\n",
    "policy = safe_learning.LinearSystem(-K, name='policy')\n",
    "policy = safe_learning.Saturation(policy, -1, 1)\n",
    "\n",
    "# Define the Lyapunov function corresponding to the known policy\n",
    "lyapunov_function = safe_learning.QuadraticFunction(P)\n",
    "grad_lyapunov_function = safe_learning.LinearSystem((-2*P,))\n",
    "\n",
    "# Lipschitz constants\n",
    "L_pol = lambda s: tf.constant(np.linalg.norm(-K, 1), dtype=tf_dtype)\n",
    "L_dyn = lambda s: np.linalg.norm(A_true, 1) + np.linalg.norm(B_true, 1)*L_pol(s)\n",
    "\n",
    "# Approximate Lipschitz constant for value function over [-1, 1]**d\n",
    "# L_V = 1.01*np.max(np.abs(session.run(lyapunov_function(states), {states: state_discretization.all_points})))\n",
    "# L_V = lambda s: tf.norm(grad_lyapunov_function(s), ord=1, axis=1, keep_dims=True)\n",
    "L_V = lambda s: tf.reduce_max(tf.abs(grad_lyapunov_function(s)), axis=1, keep_dims=True)\n",
    "\n",
    "lyapunov = safe_learning.Lyapunov(state_discretization, lyapunov_function, dynamics, L_dyn, L_V, tau, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_states = tf.placeholder(tf_dtype, shape=[None, cart_pole.state_dim], name='states')\n",
    "tf_actions = policy(tf_states)\n",
    "\n",
    "n_points = [51, 51]\n",
    "x_fix, theta_fix, x_dot_fix, theta_dot_fix = [0, 0, 0, 0]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5), dpi=100)\n",
    "fig.subplots_adjust(wspace=0.1, hspace=0.2)\n",
    "xx, yy = np.mgrid[-1:1:np.complex(0, n_points[0]), -1:1:np.complex(0, n_points[1])]\n",
    "\n",
    "# Fix x_dot and theta_dot, plot value function over x and theta\n",
    "grid = np.column_stack((xx.ravel(), yy.ravel(), \n",
    "                        x_dot_fix*np.ones_like(xx.ravel()), theta_dot_fix*np.ones_like(yy.ravel())))\n",
    "control = session.run(tf_actions, feed_dict={tf_states: grid}).reshape(n_points)\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax.plot_surface(xx, yy, control, alpha=0.75)\n",
    "ax.set_title(r'Control, $\\dot{x} = %.3g,\\ \\dot{\\theta} = %.3g$' % (x_dot_fix, theta_dot_fix), fontsize=16)\n",
    "ax.set_xlabel(r'$x$', fontsize=14)\n",
    "ax.set_ylabel(r'$\\theta$', fontsize=14)\n",
    "ax.set_zlabel(r'$u$', fontsize=14)\n",
    "# ax.view_init(elev=20., azim=15.)\n",
    "\n",
    "# Fix x and theta, plot value function over x_dot and theta_dot\n",
    "grid = np.column_stack((x_fix*np.ones_like(xx.ravel()), theta_fix*np.ones_like(yy.ravel()), \n",
    "                        xx.ravel(), yy.ravel()))\n",
    "control = session.run(tf_actions, feed_dict={tf_states: grid}).reshape(n_points)\n",
    "ax = fig.add_subplot(1, 2, 2, projection='3d')\n",
    "ax.plot_surface(xx, yy, control, alpha=0.75)\n",
    "ax.set_title(r'Control, $x = %.3g,\\ \\theta = %.3g$' % (x_fix, theta_fix), fontsize=16)\n",
    "ax.set_xlabel(r'$\\dot{x}$', fontsize=14)\n",
    "ax.set_ylabel(r'$\\dot{\\theta}$', fontsize=14)\n",
    "ax.set_zlabel(r'$u$', fontsize=14)\n",
    "# ax.view_init(elev=20., azim=100.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Safe Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial safe set (level set) based on Lyapunov function\n",
    "values = session.run(lyapunov_function(tf_states), {tf_states: state_discretization.all_points})\n",
    "cutoff = 0.01 * np.max(values)\n",
    "\n",
    "lyapunov.initial_safe_set = np.squeeze(values, axis=1) <= cutoff\n",
    "lyapunov.update_safe_set()\n",
    "\n",
    "c_max = lyapunov.feed_dict[lyapunov.c_max]\n",
    "safe_set_size_init = np.sum(lyapunov.safe_set)\n",
    "\n",
    "print('Cutoff: {}'.format(cutoff))\n",
    "print('c_max: {}'.format(c_max))\n",
    "print('Safe set size: {}'.format(safe_set_size_init))\n",
    "\n",
    "# TODO debugging\n",
    "safe_states = state_discretization.all_points[lyapunov.safe_set, :]\n",
    "tf_mean, tf_var = lyapunov.dynamics(tf_states, tf_actions)\n",
    "tf_bound = tf.reduce_sum(tf_var, axis=1, keep_dims=True)\n",
    "\n",
    "tf_lf = lyapunov.lipschitz_dynamics(tf_states)\n",
    "tf_lv = lyapunov.lipschitz_lyapunov(tf_mean)\n",
    "tf_error = tf_lv * tf_lf * tf_bound\n",
    "tf_mean_vals = lyapunov.lyapunov_function(tf_mean) \n",
    "tf_values = tf_mean_vals + tf_error\n",
    "\n",
    "tf_maps_inside = tf.less(tf_values, lyapunov.c_max)\n",
    "\n",
    "lyapunov.feed_dict.update({tf_states: safe_states})\n",
    "mean, var, bound, lf, lv, error, mean_vals, vals, maps_inside = session.run([tf_mean, tf_var, tf_bound, tf_lf, tf_lv, tf_error, \n",
    "                                                                  tf_mean_vals, tf_values, tf_maps_inside], \n",
    "                                                                 lyapunov.feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = maps_inside.squeeze(axis=1)\n",
    "bound_safe = bound[idx]\n",
    "print(idx)\n",
    "print(np.sum(idx))\n",
    "print(bound.shape)\n",
    "\n",
    "print('Policy Lipschitz constant (L_pi): {}'.format(L_pol(0).eval()))\n",
    "print('Dynamics Lipschitz constant (L_f): {}'.format(L_dyn(0).eval()))\n",
    "\n",
    "dV = session.run(grad_lyapunov_function(tf_states), {tf_states: safe_states})\n",
    "lv = session.run(L_V(tf_states), {tf_states: safe_states})\n",
    "\n",
    "print(mean)\n",
    "print(error)\n",
    "print(c_max)\n",
    "print(np.max(mean_vals))\n",
    "print(vals)\n",
    "\n",
    "# From inverted pendulum:\n",
    "# a_true, b_true = true_dynamics.linearize()\n",
    "# lipschitz_dynamics = lambda x: np.max(np.abs(a_true)) + np.max(np.abs(b_true)) * lipschitz_policy(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_safe_set(lyapunov, show=True):\n",
    "    \"\"\"Plot the safe set for a given Lyapunov function.\"\"\"\n",
    "    pos_set = np.logical_and(state_discretization.all_points[:, 2] == 0, state_discretization.all_points[:, 3] == 0)\n",
    "    vel_set = np.logical_and(state_discretization.all_points[:, 0] == 0, state_discretization.all_points[:, 1] == 0)\n",
    "    safe_pos = lyapunov.safe_set[pos_set].reshape(num_states[:2])\n",
    "    safe_vel = lyapunov.safe_set[vel_set].reshape(num_states[2:])\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 5), dpi=100)\n",
    "    fig.suptitle('Safe Set')\n",
    "    fig.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "\n",
    "    # Safe positions set, with zero velocities\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.set_title(r'$\\dot{x} = \\dot{\\theta} = 0$')\n",
    "    ax.set_xlabel(r'$x$')\n",
    "    ax.set_ylabel(r'$\\theta$')\n",
    "    im = ax.imshow(safe_pos.T,\n",
    "                   origin='lower',\n",
    "                   extent=lyapunov.discretization.limits[:2, :].ravel(),\n",
    "                   vmin=0,\n",
    "                   vmax=1)\n",
    "    fig.colorbar(im)\n",
    "    \n",
    "    # Safe velocities set, with zero positions\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.set_title(r'$x = \\theta = 0$')\n",
    "    ax.set_xlabel(r'$\\dot{x}$')\n",
    "    ax.set_ylabel(r'$\\dot{\\theta}$')\n",
    "    im = ax.imshow(safe_vel.T,\n",
    "                   origin='lower',\n",
    "                   extent=lyapunov.discretization.limits[2:, :].ravel(),\n",
    "                   vmin=0,\n",
    "                   vmax=1)\n",
    "    fig.colorbar(im)\n",
    "    \n",
    "#     if isinstance(lyapunov.dynamics, safe_learning.UncertainFunction):\n",
    "#         X = lyapunov.dynamics.functions[0].X\n",
    "#         plt.plot(X[:, 0], X[:, 1], 'rx')\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "plot_safe_set(lyapunov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Learning and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_variation = np.array([[-0.01], [0.], [0.01]], dtype=np_dtype)\n",
    "# action_variation = np.array([[0.]], dtype=np_dtype)\n",
    "\n",
    "with tf.name_scope('add_new_measurement'):\n",
    "    full_dim = cart_pole.state_dim + cart_pole.action_dim \n",
    "    tf_max_state_action = tf.placeholder(tf_dtype, shape=[1, full_dim])\n",
    "    tf_measurement = true_dynamics(tf_max_state_action)\n",
    "    \n",
    "accepted_samples = np.zeros((0, full_dim))\n",
    "        \n",
    "def update_gp(accepted_samples):\n",
    "    \"\"\"Update the GP model based on an actively selected data point.\"\"\"\n",
    "    # Get a new sample location\n",
    "    max_state_action, _ = safe_learning.get_safe_sample(lyapunov,\n",
    "                                                        action_variation,\n",
    "                                                        action_limits,\n",
    "                                                        positive=True,\n",
    "                                                        num_samples=1000)\n",
    "    # Obtain a measurement of the true dynamics\n",
    "    lyapunov.feed_dict[tf_max_state_action] = max_state_action\n",
    "    measurement = tf_measurement.eval(feed_dict=lyapunov.feed_dict)\n",
    "    \n",
    "    accepted_samples = np.concatenate((accepted_samples, max_state_action))\n",
    "    \n",
    "    # Add the measurement to our GP dynamics\n",
    "    lyapunov.dynamics.add_data_point(max_state_action, measurement)\n",
    "    \n",
    "    return accepted_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 10\n",
    "for i in tqdm(range(max_iters)):\n",
    "    accepted_samples = update_gp(accepted_samples)\n",
    "\n",
    "# Update safe set\n",
    "lyapunov.update_safe_set()\n",
    "print('Safe set size: {}'.format(np.sum(lyapunov.safe_set)))\n",
    "print('Growth: {}'.format(np.sum(lyapunov.safe_set) - safe_set_size_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accepted_samples)\n",
    "print(accepted_samples[:,:-1].dot(-K.T))\n",
    "\n",
    "# Plot new safe set\n",
    "plot_safe_set(lyapunov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_next_states = lyapunov.dynamics(tf_states, tf_actions)\n",
    "tf_decrease = lyapunov.v_decrease_bound(tf_states, tf_next_states)\n",
    "tf_threshold = lyapunov.threshold(tf_states)\n",
    "tf_negative = tf.squeeze(tf.less(tf_decrease, tf_threshold), axis=1)\n",
    "\n",
    "lyapunov.feed_dict.update({tf_states: accepted_samples[:,:-1]})\n",
    "decrease, threshold, negative = session.run([tf_decrease, tf_threshold, tf_negative], lyapunov.feed_dict)\n",
    "\n",
    "print(decrease)\n",
    "print(threshold)\n",
    "print(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
