{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability Verification for a Cart-Pole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "import safe_learning\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas\n",
    "import os\n",
    "\n",
    "from scipy.linalg import block_diag\n",
    "from utilities import CartPole, debug\n",
    "from safe_learning.utilities import get_storage, set_storage\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "%matplotlib inline\n",
    "    \n",
    "NP_DTYPE = safe_learning.config.np_dtype\n",
    "TF_DTYPE = safe_learning.config.dtype\n",
    "\n",
    "EPS = 1e-8\n",
    "\n",
    "HEAT_MAP = plt.get_cmap('inferno', lut=None)\n",
    "HEAT_MAP.set_over('white')\n",
    "HEAT_MAP.set_under('black')\n",
    "\n",
    "LEVEL_MAP = plt.get_cmap('viridis', lut=15)\n",
    "LEVEL_MAP.set_over('gold')\n",
    "LEVEL_MAP.set_under('white')\n",
    "\n",
    "pandas.options.display.float_format = '{:,.4f}'.format\n",
    "pandas.set_option('expand_frame_repr', False)\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "\n",
    "# TODO testing ****************************************#\n",
    "\n",
    "class Options(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Options, self).__init__()\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "OPTIONS = Options(np_dtype              = safe_learning.config.np_dtype,\n",
    "                  tf_dtype              = safe_learning.config.dtype,\n",
    "                  fontproperties        = FontProperties(size=10),\n",
    "                  dpi                   = 100,\n",
    "                  eps                   = 1e-8,\n",
    "                  use_linear_dynamics   = False,\n",
    "                  saturate              = True,\n",
    "                  use_zero_threshold    = False,\n",
    "                  train_hyperparameters = True,\n",
    "                  save_figs             = True,\n",
    "                  fig_path              = 'figures/cartpole_stability/')\n",
    "\n",
    "_STORAGE = {}\n",
    "\n",
    "HEAT_MAP = plt.get_cmap('inferno', lut=None)\n",
    "HEAT_MAP.set_over('white')\n",
    "HEAT_MAP.set_under('black')\n",
    "\n",
    "LEVEL_MAP = plt.get_cmap('viridis', lut=21)\n",
    "LEVEL_MAP.set_over('gold')\n",
    "LEVEL_MAP.set_under('white')\n",
    "\n",
    "# BINARY_MAP = ListedColormap([(1., 1., 1., 0.), (0., 1., 0., 0.65)])\n",
    "\n",
    "def binary_cmap(color='red', alpha=1.):\n",
    "    if color=='red':\n",
    "        color_code = (1., 0., 0., alpha)\n",
    "    elif color=='green':\n",
    "        color_code = (0., 1., 0., alpha)\n",
    "    elif color=='blue':\n",
    "        color_code = (0., 0., 1., alpha)\n",
    "    else:\n",
    "        color_code = color\n",
    "    transparent_code = (1., 1., 1., 0.)\n",
    "    return ListedColormap([transparent_code, color_code])\n",
    "\n",
    "#******************************************************#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CPU_COUNT = os.cpu_count()\n",
    "NUM_CORES = 8\n",
    "NUM_SOCKETS = 2\n",
    "\n",
    "os.environ[\"KMP_BLOCKTIME\"]    = str(0)\n",
    "os.environ[\"KMP_SETTINGS\"]     = str(1)\n",
    "os.environ[\"KMP_AFFINITY\"]     = 'granularity=fine,noverbose,compact,1,0'\n",
    "os.environ[\"OMP_NUM_THREADS\"]  = str(NUM_CORES)\n",
    "\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads  = NUM_CORES,\n",
    "                        inter_op_parallelism_threads  = NUM_SOCKETS,\n",
    "                        allow_soft_placement          = False,\n",
    "#                         log_device_placement          = True,\n",
    "                        device_count                  = {'CPU': MAX_CPU_COUNT})\n",
    "\n",
    "# TODO manually for CPU-only?\n",
    "config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\n",
    "\n",
    "try:\n",
    "    session.close()\n",
    "except NameError:\n",
    "    pass\n",
    "session = tf.InteractiveSession(config=config)\n",
    "\n",
    "# print('Found MAX_CPU_COUNT =', MAX_CPU_COUNT)\n",
    "# for dev in session.list_devices():\n",
    "#     print(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Saturate the action so that it lies in [-1, 1]\n",
    "SATURATE = True\n",
    "\n",
    "# Use the true physical parameters in the GP model\n",
    "USE_TRUE_PARAMETERS = False\n",
    "\n",
    "# Use the linearized discrete-time model as the true underlying dynamics\n",
    "USE_LINEAR_DYNAMICS = False\n",
    "\n",
    "# Use a threshold of zero when checking for stability\n",
    "USE_ZERO_THRESHOLD = False\n",
    "\n",
    "#\n",
    "USE_LINEAR_KERNELS = False\n",
    "\n",
    "#\n",
    "USE_LIPSCHITZ_SCALING = True\n",
    "\n",
    "# Scaling factor for GP confidence intervals\n",
    "BETA = 2.\n",
    "\n",
    "#\n",
    "GP_SCALING = 1e3\n",
    "\n",
    "#\n",
    "NOISE_VAR = 0.001 ** 2\n",
    "\n",
    "#\n",
    "ADAPTIVE = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "dt = 0.01   # sampling time\n",
    "g  = 9.81   # gravity\n",
    "\n",
    "# True system parameters\n",
    "m = 0.175    # pendulum mass\n",
    "M = 1.732    # cart mass\n",
    "L = 0.28     # pole length\n",
    "b = 0.01     # rotational friction\n",
    "\n",
    "# State and action normalizers\n",
    "x_max     = 0.5\n",
    "theta_max = np.deg2rad(30)\n",
    "v_max     = 2.\n",
    "omega_max = np.deg2rad(30)\n",
    "u_max     = (m + M) * (v_max ** 2) / x_max\n",
    "\n",
    "state_norm = (x_max, theta_max, v_max, omega_max)\n",
    "action_norm = (u_max, )\n",
    "\n",
    "# Constraints for initial 'safe' states\n",
    "x_safe     = x_max\n",
    "theta_safe = 0.3 * theta_max\n",
    "v_safe     = 0.5 * v_max\n",
    "omega_safe = 0.25 * omega_max\n",
    "safe_norm  = np.array([[x_safe / x_max, theta_safe / theta_max, v_safe / v_max, omega_safe / omega_max]])\n",
    "\n",
    "# Dimensions and domains\n",
    "state_dim     = 4\n",
    "action_dim    = 1\n",
    "state_limits  = np.array([[-1., 1.]] * state_dim)\n",
    "action_limits = np.array([[-1., 1.]] * action_dim)\n",
    "\n",
    "# True system\n",
    "true_cartpole = CartPole(m, M, L, b, dt, [state_norm, action_norm])\n",
    "A_true, B_true = true_cartpole.linearize()\n",
    "\n",
    "if USE_LINEAR_DYNAMICS:\n",
    "    true_dynamics = safe_learning.functions.LinearSystem((A_true, B_true), name='true_dynamics')\n",
    "else:\n",
    "    true_dynamics = true_cartpole.__call__\n",
    "\n",
    "# \"Wrong\" system\n",
    "m = 0.2     # pendulum mass\n",
    "M = 1.5     # cart mass\n",
    "L = 0.25    # pole length\n",
    "b = 0.0     # rotational friction\n",
    "cartpole = CartPole(m, M, L, b, dt, [state_norm, action_norm])\n",
    "A, B = cartpole.linearize()\n",
    "\n",
    "if USE_TRUE_PARAMETERS:\n",
    "    A = A_true\n",
    "    B = B_true\n",
    "mean_dynamics = safe_learning.LinearSystem((A, B), name='mean_dynamics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m_true = np.hstack((A_true, B_true))\n",
    "m = np.hstack((A, B))\n",
    "variances = (m_true - m) ** 2\n",
    "\n",
    "# Make sure at least some non-zero prior variance is maintained\n",
    "np.clip(variances, 1e-3, None, out=variances)\n",
    "\n",
    "# Measurement noise\n",
    "noise_var = NOISE_VAR\n",
    "\n",
    "# Input to GP is of the form (x,u)\n",
    "full_dim = state_dim + action_dim\n",
    "\n",
    "# Kernels\n",
    "if USE_LINEAR_KERNELS:\n",
    "    kernel_x = gpflow.kernels.Linear(full_dim, variance=variances[0, :], ARD=True)\n",
    "    \n",
    "    kernel_theta = gpflow.kernels.Linear(full_dim, variance=variances[1, :], ARD=True)\n",
    "\n",
    "    kernel_v = gpflow.kernels.Linear(full_dim, variance=variances[2, :], ARD=True)\n",
    "\n",
    "    kernel_omega = gpflow.kernels.Linear(full_dim, variance=variances[3, :], ARD=True)\n",
    "\n",
    "else:\n",
    "    kernel_x = (gpflow.kernels.Linear(full_dim, variance=variances[0, :], ARD=True)\n",
    "                + (  gpflow.kernels.Linear(1, variance=variances[0, 1], active_dims=[1])                   # theta\n",
    "                   + gpflow.kernels.Matern32(1, variance=variances[0, 3], lengthscales=1, active_dims=[3]) # omega\n",
    "                   + gpflow.kernels.Linear(1, variance=variances[0, 4], active_dims=[4])                   # u\n",
    "                 ) * gpflow.kernels.Matern32(1, lengthscales=1, active_dims=[1]) \n",
    "    )\n",
    "\n",
    "    kernel_theta = (gpflow.kernels.Linear(full_dim, variance=variances[1, :], ARD=True)\n",
    "                    + (  gpflow.kernels.Linear(1, variance=variances[1, 1], active_dims=[1])                   # theta\n",
    "                       + gpflow.kernels.Matern32(1, variance=variances[1, 3], lengthscales=1, active_dims=[3]) # omega\n",
    "                       + gpflow.kernels.Linear(1, variance=variances[1, 4], active_dims=[4])                   # u\n",
    "                     ) * gpflow.kernels.Matern32(1, lengthscales=1, active_dims=[1])\n",
    "    )\n",
    "\n",
    "    kernel_v = (gpflow.kernels.Linear(full_dim, variance=variances[2, :], ARD=True) \n",
    "                + (  gpflow.kernels.Linear(1, variance=variances[2, 1], active_dims=[1])                   # theta\n",
    "                   + gpflow.kernels.Matern32(1, variance=variances[2, 3], lengthscales=1, active_dims=[3]) # omega\n",
    "                   + gpflow.kernels.Linear(1, variance=variances[2, 4], active_dims=[4])                   # u\n",
    "                 ) * gpflow.kernels.Matern32(1, lengthscales=1, active_dims=[1]) \n",
    "    )\n",
    "\n",
    "    kernel_omega = (gpflow.kernels.Linear(full_dim, variance=variances[3, :], ARD=True)\n",
    "                    + (  gpflow.kernels.Linear(1, variance=variances[3, 1], active_dims=[1])                   # theta\n",
    "                       + gpflow.kernels.Matern32(1, variance=variances[3, 3], lengthscales=1, active_dims=[3]) # omega\n",
    "                       + gpflow.kernels.Linear(1, variance=variances[3, 4], active_dims=[4])                   # u\n",
    "                     ) * gpflow.kernels.Matern32(1, lengthscales=1, active_dims=[1])\n",
    "    )\n",
    "\n",
    "# Mean dynamics\n",
    "mean_function_x = safe_learning.LinearSystem((A[[0], :], B[[0], :]), name='mean_dynamics_x')\n",
    "mean_function_theta = safe_learning.LinearSystem((A[[1], :], B[[1], :]), name='mean_dynamics_theta')\n",
    "mean_function_v = safe_learning.LinearSystem((A[[2], :], B[[2], :]), name='mean_dynamics_v')\n",
    "mean_function_omega = safe_learning.LinearSystem((A[[3], :], B[[3], :]), name='mean_dynamics_omega')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define a GP model over the dynamics\n",
    "X_init = np.zeros((1, full_dim), dtype=NP_DTYPE)\n",
    "Y_init = np.zeros((1, 1), dtype=NP_DTYPE)\n",
    "\n",
    "gp_x = gpflow.gpr.GPR(X_init, Y_init, kernel_x, mean_function_x)\n",
    "gp_theta = gpflow.gpr.GPR(X_init, Y_init, kernel_theta, mean_function_theta)\n",
    "gp_v = gpflow.gpr.GPR(X_init, Y_init, kernel_v, mean_function_v)\n",
    "gp_omega = gpflow.gpr.GPR(X_init, Y_init, kernel_omega, mean_function_omega)\n",
    "\n",
    "\n",
    "\n",
    "# TODO Tensorflow spits out a lot of allocator errors when creating 0-length dataholders in gpflow. Occurs when:\n",
    "#     - initializing with empty data matrices X and Y\n",
    "#     - using GPRCached (initializes empty dataholders for Cholesky decomposition)\n",
    "\n",
    "# X_init = np.empty((0, full_dim), dtype=NP_DTYPE)\n",
    "# Y_init = np.empty((0, 1), dtype=NP_DTYPE)\n",
    "\n",
    "# gp_x = safe_learning.GPRCached(X_init, Y_init, kernel_x, mean_function_x, scaling=GP_SCALING)\n",
    "# gp_theta = safe_learning.GPRCached(X_init, Y_init, kernel_theta, mean_function_theta, scaling=GP_SCALING)\n",
    "# gp_v = safe_learning.GPRCached(X_init, Y_init, kernel_v, mean_function_v, scaling=GP_SCALING)\n",
    "# gp_omega = safe_learning.GPRCached(X_init, Y_init, kernel_omega, mean_function_omega, scaling=GP_SCALING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gp_x.likelihood.variance = noise_var\n",
    "gp_theta.likelihood.variance = noise_var\n",
    "gp_v.likelihood.variance = noise_var\n",
    "gp_omega.likelihood.variance = noise_var\n",
    "\n",
    "gp_x_fun = safe_learning.GaussianProcess(gp_x, BETA)\n",
    "gp_theta_fun = safe_learning.GaussianProcess(gp_theta, BETA)\n",
    "gp_v_fun = safe_learning.GaussianProcess(gp_v, BETA)\n",
    "gp_omega_fun = safe_learning.GaussianProcess(gp_omega, BETA)\n",
    "\n",
    "# Stack GP functions => block-diagonal kernel matrix\n",
    "dynamics = safe_learning.FunctionStack((gp_x_fun, gp_theta_fun, gp_v_fun, gp_omega_fun))\n",
    "\n",
    "def optimize_gp_hyperparameters(lyapunov, X=None, Y=None, print_params=False):\n",
    "    \"\"\"Optimize GP hyperparameters via MLE on a given data set.\"\"\"\n",
    "    \n",
    "    print('Optimizing ...')\n",
    "    \n",
    "    for i, gp in enumerate(lyapunov.dynamics.functions):\n",
    "        if print_params:\n",
    "            print('Original parameters:\\n', gp.gaussian_process, '\\n')\n",
    "\n",
    "        X_save = gp.gaussian_process.X.value\n",
    "        Y_save = gp.gaussian_process.Y.value\n",
    "        \n",
    "        if X is not None:\n",
    "            gp.gaussian_process.X = X\n",
    "        if Y is not None:\n",
    "            gp.gaussian_process.Y = Y[:, i].reshape((-1, 1))\n",
    "        gp.update_feed_dict()\n",
    "\n",
    "        gp.gaussian_process.optimize()\n",
    "       \n",
    "        # Reset GP data matrices\n",
    "        gp.gaussian_process.X = X_save\n",
    "        gp.gaussian_process.Y = Y_save\n",
    "\n",
    "        with tf.variable_scope(gp.scope_name):\n",
    "            gp.gaussian_process.make_tf_array(gp.hyperparameters[0])\n",
    "            gp.update_feed_dict()\n",
    "        \n",
    "        if print_params:\n",
    "            print('New parameters:\\n', gp.gaussian_process, '\\n')\n",
    "        \n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of states along each dimension\n",
    "num_states = 51\n",
    "\n",
    "# State grid\n",
    "grid_limits = np.array([[-1., 1.], [-1., 1.], [-1., 1.], [-1., 1.]])\n",
    "state_discretization = safe_learning.GridWorld(grid_limits, num_states)\n",
    "\n",
    "# Discretization constant\n",
    "if USE_ZERO_THRESHOLD:\n",
    "    tau = 0.0\n",
    "else:\n",
    "    tau = np.sum(state_discretization.unit_maxes) / 2\n",
    "\n",
    "print('Grid size: {}'.format(state_discretization.nindex))\n",
    "print('Discretization constant: {}'.format(tau))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# State cost matrix\n",
    "Q = np.diag([0.1, 0.1, 0.1, 0.1]).astype(NP_DTYPE)\n",
    "\n",
    "# Action cost matrix\n",
    "R = 0.1 * np.identity(action_dim).astype(NP_DTYPE)\n",
    "\n",
    "# Normalize cost matrices\n",
    "# cost_norm = np.max([Q.max(), R.max()])\n",
    "# Q = Q / cost_norm\n",
    "# R = R / cost_norm\n",
    "\n",
    "# Quadratic cost function\n",
    "cost_function = safe_learning.QuadraticFunction(block_diag(Q, R), name='cost_function')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix policy to the LQR solution for the true system\n",
    "K, P = safe_learning.utilities.dlqr(A_true, B_true, Q, R)\n",
    "policy = safe_learning.LinearSystem(-K, name='policy')\n",
    "\n",
    "if SATURATE:\n",
    "    policy = safe_learning.Saturation(policy, -1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_policy(lyapunov, tf_states, fixed_state, state_norm=None):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5), dpi=300)\n",
    "    fig.subplots_adjust(wspace=0.4, hspace=0.2)\n",
    "    ticks = np.linspace(-1., 1., 9)\n",
    "    cutoff = 1. - 1e-5\n",
    "    \n",
    "    fixed_state = np.asarray(fixed_state, dtype=NP_DTYPE)\n",
    "    for i in range(4):\n",
    "        dist = np.square(lyapunov.discretization.discrete_points[i] - fixed_state[i])\n",
    "        idx = np.argmin(dist)\n",
    "        fixed_state[i] = lyapunov.discretization.discrete_points[i][idx]\n",
    "    x_fix, theta_fix, v_fix, omega_fix = fixed_state\n",
    "    pos_set = np.logical_and(lyapunov.discretization.all_points[:, 1] == theta_fix, lyapunov.discretization.all_points[:, 3] == omega_fix)\n",
    "    vel_set = np.logical_and(lyapunov.discretization.all_points[:, 0] == x_fix, lyapunov.discretization.all_points[:, 2] == v_fix)\n",
    "    \n",
    "    if state_norm is not None:\n",
    "        x_max, theta_max, v_max, omega_max = state_norm\n",
    "        scale = np.array([x_max, np.rad2deg(theta_max), v_max, np.rad2deg(omega_max)]).reshape((-1, 1))\n",
    "        limits = scale * lyapunov.discretization.limits\n",
    "        x_fix, theta_fix, v_fix, omega_fix = fixed_state * scale.ravel()\n",
    "    else:\n",
    "        limits = lyapunov.discretization.limits\n",
    "    \n",
    "    # Fix v and omega, plot policy over x and theta\n",
    "    grid = lyapunov.discretization.all_points[pos_set, :]\n",
    "    z = session.run(lyapunov.policy(tf_states), feed_dict={tf_states: grid}).reshape(lyapunov.discretization.num_points[[0, 2]])\n",
    "    im = ax[0].imshow(z.T, origin='lower', extent=limits[(0, 2), :].ravel(), aspect=limits[0, 0] / limits[2, 0], cmap=HEAT_MAP, vmin=-cutoff, vmax=cutoff)\n",
    "    cbar = fig.colorbar(im, ax=ax[0], label=r'$u = \\pi(x)$', ticks=ticks)\n",
    "    ax[0].set_title(r'$\\theta = %.3g$ deg, $\\omega = %.3g$ deg/s' % (theta_fix, omega_fix))\n",
    "    ax[0].set_xlabel(r'$x$ [m]')\n",
    "    ax[0].set_ylabel(r'$v$ [m/s]')\n",
    "  \n",
    "    # Fix x and theta, plot policy over v and omega\n",
    "    grid = lyapunov.discretization.all_points[vel_set, :]\n",
    "    z = session.run(lyapunov.policy(tf_states), feed_dict={tf_states: grid}).reshape(lyapunov.discretization.num_points[[1, 3]])\n",
    "    im = ax[1].imshow(z.T, origin='lower', extent=limits[(1, 3), :].ravel(), aspect=limits[1, 0] / limits[3, 0], cmap=HEAT_MAP, vmin=-cutoff, vmax=cutoff)\n",
    "    cbar = fig.colorbar(im, ax=ax[1], label=r'$u = \\pi(x)$', ticks=ticks)\n",
    "    ax[1].set_title(r'$x = %.3g$ m, $v = %.3g$ m/s' % (x_fix, v_fix))\n",
    "    ax[1].set_xlabel(r'$\\theta$ [deg]')\n",
    "    ax[1].set_ylabel(r'$\\omega$ [deg/s]')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Visualize policy\n",
    "# fixed_state = [0., 0., 0., 0.]\n",
    "# plot_policy(lyapunov, tf.placeholder(OPTIONS.tf_dtype, shape=[None, state_dim], name='temp_states'), fixed_state, state_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyapunov Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the Lyapunov function corresponding to the known policy\n",
    "lyapunov_function = safe_learning.QuadraticFunction(P)\n",
    "grad_lyapunov_function = safe_learning.LinearSystem((2*P,))\n",
    "\n",
    "# Lipschitz constants\n",
    "L_pol = lambda s: tf.constant(np.linalg.norm(-K, 1), dtype=TF_DTYPE)\n",
    "L_dyn = lambda s: np.linalg.norm(A_true, 1) + np.linalg.norm(B_true, 1)*L_pol(s)\n",
    "\n",
    "if USE_LIPSCHITZ_SCALING:\n",
    "    L_v = lambda s: tf.abs(grad_lyapunov_function(s))\n",
    "else:\n",
    "    L_v = lambda s: tf.norm(grad_lyapunov_function(s), ord=1, axis=1, keep_dims=True)\n",
    "    \n",
    "# Set initial safe set as a level set of the Lyapunov function\n",
    "states = tf.placeholder(OPTIONS.tf_dtype, shape=[None, state_dim], name='temp_states')\n",
    "values = lyapunov_function(states).eval({states: state_discretization.all_points})\n",
    "cutoff = 5e-3 * np.max(values)\n",
    "initial_safe_set = np.squeeze(values, axis=1) <= cutoff\n",
    "\n",
    "# Set initial safe set as a hypercube in the state space\n",
    "# norm_states = state_discretization.all_points / safe_norm\n",
    "# initial_safe_set = np.all(np.logical_and(norm_states >= -1, norm_states <= 1), axis=1, keepdims=False)\n",
    "\n",
    "# Initialize class\n",
    "print('Initializing ...')\n",
    "lyapunov = safe_learning.Lyapunov(state_discretization, lyapunov_function, dynamics, \n",
    "                                  L_dyn, L_v, tau, policy, initial_safe_set, adaptive=ADAPTIVE)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = get_storage(_STORAGE)\n",
    "if storage is None:\n",
    "    # Current\n",
    "    states = tf.placeholder(OPTIONS.tf_dtype, shape=[None, lyapunov.discretization.ndim], name='states')\n",
    "    actions = policy(states)\n",
    "    values = lyapunov.lyapunov_function(states)\n",
    "    \n",
    "    # Predicted future\n",
    "    future_states_mean, future_states_error = lyapunov.dynamics(states, actions)\n",
    "    future_values_mean = lyapunov.lyapunov_function(future_states_mean)\n",
    "    lv = lyapunov.lipschitz_lyapunov(future_states_mean)\n",
    "    future_values_error = tf.reduce_sum(lv * future_states_error, axis=1, keepdims=True)\n",
    "    dv_mean = future_values_mean - values\n",
    "    dv_bound = dv_mean + future_values_error\n",
    "    \n",
    "    # True future\n",
    "    future_states = true_dynamics(states, actions)\n",
    "    future_values = lyapunov.lyapunov_function(future_states)\n",
    "    dv = future_values - values\n",
    "    \n",
    "    # Discretization effects\n",
    "    tau = tf.placeholder(OPTIONS.tf_dtype, shape=[None, 1], name='discretization_constant')\n",
    "    threshold = lyapunov.threshold(states, tau)\n",
    "    negative = tf.less(dv_bound, threshold)\n",
    "    \n",
    "    # Place into storage\n",
    "    storage = [('states', states), ('actions', actions), ('values', values), \n",
    "               ('future_states', future_states), ('future_values', future_values), ('dv', dv),\n",
    "               ('tau', tau), ('threshold', threshold), ('negative', negative)]\n",
    "    set_storage(_STORAGE, storage)\n",
    "else:\n",
    "    # Get from storage\n",
    "    states, actions, values, future_states, future_values, dv, tau, threshold, negative  = storage.values()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Lyapunov ROA and Discretization Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value, sorted_1d=True):\n",
    "    if not sorted_1d:\n",
    "        array = np.sort(array)\n",
    "    idx = np.searchsorted(array, value, side='left')\n",
    "    if idx > 0 and (idx == len(array) or np.abs(value - array[idx - 1]) < np.abs(value - array[idx])):\n",
    "        idx -= 1\n",
    "    return idx, array[idx]\n",
    "\n",
    "\n",
    "def gridify(norms, maxes=None, num_points=25):    \n",
    "    norms = np.asarray(norms).ravel()\n",
    "    if maxes is None:\n",
    "        maxes = norms\n",
    "    else:\n",
    "        maxes = np.asarray(maxes).ravel()\n",
    "    limits = np.column_stack((- maxes / norms, maxes / norms))\n",
    "    \n",
    "    if isinstance(num_points, int):\n",
    "        num_points = [num_points, ] * len(norms)\n",
    "    grid = safe_learning.GridWorld(limits, num_points)\n",
    "    return grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = np.asarray([x_max, np.rad2deg(theta_max), v_max, np.rad2deg(omega_max)])\n",
    "maxes = np.copy(norms)\n",
    "grid = lyapunov.discretization\n",
    "\n",
    "# Snap fixed_state to the closest grid point\n",
    "fixed_state = np.asarray([0., 0., 0., 0.], dtype=OPTIONS.np_dtype)\n",
    "fixed_index = np.zeros_like(fixed_state, dtype=int)\n",
    "for d in range(grid.ndim):\n",
    "    fixed_index[d], fixed_state[d] = find_nearest(grid.discrete_points[d], fixed_state[d])\n",
    "\n",
    "# Get 2d-planes of the discretization (x vs. v, theta vs. omega) according to fixed_state\n",
    "planes = [[1, 3], [0, 2]]\n",
    "grid_slices = []\n",
    "for p in planes:\n",
    "    grid_slices.append(np.logical_and(grid.all_points[:, p[0]] == fixed_state[p[0]], \n",
    "                                      grid.all_points[:, p[1]] == fixed_state[p[1]]).ravel())\n",
    "\n",
    "# Adaptive discretization\n",
    "refinements = []\n",
    "for mask in grid_slices:\n",
    "    feed_dict = {states: grid.all_points[mask], tau: [[np.sum(grid.unit_maxes) / 2]]}\n",
    "    N = (threshold / dv).eval(feed_dict)\n",
    "    N[np.isnan(N)] = -1\n",
    "    N[N < 0] = -1\n",
    "    N = np.ceil(N)\n",
    "    refinements.append(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 16\n",
    "plt.rc('font', size=fontsize)\n",
    "\n",
    "Nmax = 2000\n",
    "cmap = plt.get_cmap('viridis', lut=Nmax)\n",
    "cmap.set_over('gold')\n",
    "cmap.set_under((1., 1., 1., 0.))\n",
    "plot_limits = np.asarray(norms).reshape((-1, 1)) * grid.limits\n",
    "pad = 10\n",
    "\n",
    "# fig.subplots_adjust(wspace=0.4)\n",
    "\n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(8, 8), dpi=OPTIONS.dpi)\n",
    "fig2, ax2 = plt.subplots(1, 1, figsize=(8, 8), dpi=OPTIONS.dpi)\n",
    "\n",
    "for i, (p, N, fig, ax) in enumerate(zip(planes[::-1], refinements, [fig1, fig2], [ax1, ax2])):\n",
    "    z = N.reshape(grid.num_points[p])\n",
    "    im = ax.imshow(z.T, origin='lower', extent=plot_limits[p].ravel(), aspect=plot_limits[p[0], 1] / plot_limits[p[1], 1], \n",
    "                   cmap=cmap, vmin=0, vmax=Nmax)\n",
    "    cbar = fig.colorbar(im, ax=ax, label=r'$N({\\bf x})$')\n",
    "    grid_string = (r'$M = {}$'.format(grid.num_points[0] - 1) \n",
    "                   + ',  ' + r'$|\\mathcal{X}_\\tau|$ = ' + r'{:.1e}'.format((grid.num_points[0] - 1) ** grid.ndim) \n",
    "                   + ',  ' + r'$\\tau$ = ' + r'{:.0e}'.format(np.sum(grid.unit_maxes) / 2))\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.set_title(r'$\\phi = \\dot{\\phi} = 0$' + '\\n' + grid_string, fontsize=fontsize)\n",
    "        ax.set_xlabel(r'$x$ [m]', labelpad=pad)\n",
    "        ax.set_ylabel(r'$\\dot{x}$ [m/s]', labelpad=pad)\n",
    "    else:\n",
    "        ax.set_title(r'$x = \\dot{x} = 0$' + '\\n' + grid_string, fontsize=fontsize)\n",
    "        ax.set_xlabel(r'$\\phi$ [deg]', labelpad=pad)\n",
    "        ax.set_ylabel(r'$\\dot{\\phi}$ [deg/s]', labelpad=pad)\n",
    "\n",
    "    yticks = cbar.ax.get_yticks()\n",
    "    tick_labels = ['{:.0f}'.format(y * Nmax) for y in yticks]\n",
    "    tick_labels[-1] = r'$\\geq {}$'.format(Nmax)\n",
    "    cbar.ax.set_yticklabels(tick_labels)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "if OPTIONS.save_figs:\n",
    "    fig1.savefig(OPTIONS.fig_path + 'cartpole_stability_Nreq_x.pdf', bbox_inches='tight')\n",
    "    fig2.savefig(OPTIONS.fig_path + 'cartpole_stability_Nreq_phi.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid for computing c_max\n",
    "N = 51\n",
    "norms = np.asarray([x_max, np.rad2deg(theta_max), v_max, np.rad2deg(omega_max)])\n",
    "maxes = np.copy(norms)\n",
    "grid = gridify(norms, maxes, N)\n",
    "\n",
    "vals, true_dv = session.run([values, dv], {states: grid.all_points})\n",
    "D = (true_dv < 0).ravel()\n",
    "\n",
    "# Set value order\n",
    "value_order = np.argsort(vals.ravel())\n",
    "safe        = D[value_order]\n",
    "safe[0]     = True                        # set origin to be safe\n",
    "max_index   = np.argmin(safe) - 1         # argmin returns index of first False, otherwise 0\n",
    "\n",
    "c_max = vals[value_order[max_index]]\n",
    "V_max = (vals <= c_max).ravel()\n",
    "\n",
    "print(c_max)\n",
    "print(D.sum() / grid.nindex)\n",
    "print(V_max.sum())\n",
    "\n",
    "\n",
    "# #------------------------------------------------------------------------------#\n",
    "# # Grid for nice plotting\n",
    "# N = 151\n",
    "# grid = gridify(norms, maxes, N)\n",
    "\n",
    "# # Snap fixed_state to the closest grid point\n",
    "# fixed_state = np.asarray([0., 0., 0., 0.], dtype=OPTIONS.np_dtype)\n",
    "# fixed_index = np.zeros_like(fixed_state, dtype=int)\n",
    "# for d in range(grid.ndim):\n",
    "#     fixed_index[d], fixed_state[d] = find_nearest(grid.discrete_points[d], fixed_state[d])\n",
    "\n",
    "# # Get 2d-planes of the discretization (x vs. v, theta vs. omega) according to fixed_state\n",
    "# planes = [[1, 3], [0, 2]]\n",
    "# grid_slices = []\n",
    "# for p in planes:\n",
    "#     grid_slices.append(np.logical_and(grid.all_points[:, p[0]] == fixed_state[p[0]], \n",
    "#                                       grid.all_points[:, p[1]] == fixed_state[p[1]]).ravel())\n",
    "\n",
    "# decrease_sets = [(dv.eval({states: grid.all_points[mask]}) < 0).ravel() for mask in grid_slices]\n",
    "# safe_sets = [(values.eval({states: grid.all_points[mask]}) <= c_max).ravel() for mask in grid_slices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fontsize = 16\n",
    "# plt.rc('font', size=fontsize)\n",
    "\n",
    "# colors      = [(1., 1., 1., 0.), (0., 0., 0., 0.3), (1., 0., 0., 0.75)]\n",
    "# cmap        = ListedColormap(colors)\n",
    "# plot_limits = np.asarray(norms).reshape((-1, 1)) * grid.limits\n",
    "# pad         = 10\n",
    "\n",
    "# # fig.subplots_adjust(wspace=0.4)\n",
    "# fig1, ax1 = plt.subplots(1, 1, figsize=(8, 8), dpi=OPTIONS.dpi)\n",
    "# fig2, ax2 = plt.subplots(1, 1, figsize=(8, 8), dpi=OPTIONS.dpi)\n",
    "\n",
    "# for i, (p, dec, safe, fig, ax) in enumerate(zip(planes[::-1], decrease_sets, safe_sets, [fig1, fig2], [ax1, ax2])):\n",
    "#     z = (dec.astype(int) + safe.astype(int)).reshape(grid.num_points[p])\n",
    "#     z[75, 75] = 2\n",
    "#     im = ax.imshow(z.T, origin='lower', extent=plot_limits[p].ravel(), aspect=plot_limits[p[0], 1] / plot_limits[p[1], 1], cmap=cmap)\n",
    "    \n",
    "#     if i == 0:\n",
    "#         ax.set_title(r'$\\phi = \\dot{\\phi} = 0$' + '\\n', fontsize=fontsize)\n",
    "#         ax.set_xlabel(r'$x$ [m]', labelpad=pad)\n",
    "#         ax.set_ylabel(r'$\\dot{x}$ [m/s]', labelpad=pad)\n",
    "#     else:\n",
    "#         ax.set_title(r'$x = \\dot{x} = 0$' + '\\n', fontsize=fontsize)\n",
    "#         ax.set_xlabel(r'$\\phi$ [deg]', labelpad=pad)\n",
    "#         ax.set_ylabel(r'$\\dot{\\phi}$ [deg/s]', labelpad=pad)\n",
    "\n",
    "#     proxy = [plt.Rectangle((0,0), 1, 1, fc=c) for c in colors[1:]]\n",
    "#     labels = [r'$\\mathcal{D}$',\n",
    "#               r'$\\mathcal{V}\\!\\ (c_{max})$']\n",
    "#     ax.legend(proxy, labels, loc='upper right')\n",
    "        \n",
    "# plt.show()\n",
    "# if OPTIONS.save_figs:\n",
    "#     fig1.savefig(OPTIONS.fig_path + 'cartpole_stability_Vmax_x.pdf', bbox_inches='tight')\n",
    "#     fig2.savefig(OPTIONS.fig_path + 'cartpole_stability_Vmax_phi.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True ROA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roa(grid, closed_loop_dynamics, horizon=250, tol=1e-3, equilibrium=None, no_traj=True):\n",
    "    # Forward-simulate all trajectories from initial points in the discretization\n",
    "    if no_traj:\n",
    "        end_states = grid.all_points\n",
    "        for t in range(1, horizon):\n",
    "            end_states = closed_loop_dynamics(end_states)\n",
    "    else:\n",
    "        trajectories = np.empty((grid.nindex, grid.ndim, horizon))\n",
    "        trajectories[:, :, 0] = grid.all_points\n",
    "        for t in range(1, horizon):\n",
    "            trajectories[:, :, t] = closed_loop_dynamics(trajectories[:, :, t - 1])\n",
    "        end_states = trajectories[:, :, -1]\n",
    "            \n",
    "    if equilibrium is None:\n",
    "        equilibrium = np.zeros((1, grid.ndim))\n",
    "    \n",
    "    # Compute an approximate ROA as all states that end up \"close\" to 0\n",
    "    dists = np.linalg.norm(end_states - equilibrium, ord=2, axis=1, keepdims=True).ravel()\n",
    "    roa = (dists <= tol)\n",
    "    if no_traj:\n",
    "        return roa, dists\n",
    "    else:\n",
    "        return roa, dists, trajectories\n",
    "\n",
    "\n",
    "grid = lyapunov.discretization\n",
    "closed_loop_dynamics = lambda x: future_states.eval({states: x})\n",
    "horizon = 500\n",
    "tol     = 0.1\n",
    "\n",
    "# roa, _ = compute_roa(grid, closed_loop_dynamics, horizon, tol, no_traj=True)\n",
    "# print(roa.sum() / grid.nindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Training via MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OPTIONS.train_hyperparameters:\n",
    "    # Sample safe state-action pairs (x, u) and observations from the dynamics\n",
    "    num_samples = int(1e3)\n",
    "    safe_states = lyapunov.discretization.all_points[lyapunov.safe_set.ravel()]\n",
    "    idx = np.random.choice(safe_states.shape[0], num_samples, replace=False)\n",
    "    training_states = safe_states[idx, :]\n",
    "    training_actions = lyapunov.policy(training_states).eval()\n",
    "    X = np.concatenate((training_states, training_actions), axis=1)\n",
    "    Y = true_dynamics(training_states, training_actions).eval()\n",
    "    optimize_gp_hyperparameters(lyapunov, X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Safe Set Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare safe set before and after checking the decrease condition for the first time\n",
    "c_max = lyapunov.feed_dict[lyapunov.c_max]\n",
    "init_safe_set_size = np.sum(lyapunov.safe_set)\n",
    "\n",
    "print('Before update ...')\n",
    "print('c_max: {}'.format(c_max))\n",
    "print('Safe set size: {}\\n'.format(init_safe_set_size))\n",
    "\n",
    "# old_safe_set = np.copy(lyapunov.safe_set)\n",
    "lyapunov.update_safe_set()\n",
    "\n",
    "c_max = lyapunov.feed_dict[lyapunov.c_max]\n",
    "init_safe_set_size = lyapunov.safe_set.sum()\n",
    "\n",
    "print('After update ...')\n",
    "print('c_max: {}'.format(c_max))\n",
    "print('Safe set size: {}'.format(init_safe_set_size))\n",
    "\n",
    "# debug(lyapunov, true_dynamics, state_norm, Nmax=50, plot='cartpole')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Learning and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# action_variation = np.array([-0.1, -0.01, -0.001, 0., 0.001, 0.01, 0.1], dtype=np_dtype).reshape((-1, 1))\n",
    "action_variation = np.array([0.], dtype=NP_DTYPE).reshape((-1, 1))\n",
    "\n",
    "with tf.name_scope('add_new_measurement'):\n",
    "    full_dim = state_dim + action_dim \n",
    "    tf_max_state_action = tf.placeholder(TF_DTYPE, shape=[1, full_dim])\n",
    "    tf_measurement = true_dynamics(tf_max_state_action)\n",
    "    \n",
    "def update_gp():\n",
    "    \"\"\"Update the GP model based on an actively selected data point.\"\"\"\n",
    "    \n",
    "    # Get a new sample location\n",
    "    max_state_action, _ = safe_learning.get_safe_sample(lyapunov, action_variation, action_limits, positive=True, num_samples=1000)\n",
    "    \n",
    "    # Obtain a measurement of the true dynamics\n",
    "    lyapunov.feed_dict[tf_max_state_action] = max_state_action\n",
    "    measurement = tf_measurement.eval(feed_dict=lyapunov.feed_dict)\n",
    "    \n",
    "    # Add the measurement to our GP dynamics\n",
    "    lyapunov.dynamics.add_data_point(max_state_action, measurement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_update = 0\n",
    "safe_set_updates = 1\n",
    "\n",
    "batch_size          = int(1e3)\n",
    "can_shrink          = True\n",
    "n_max               = 5000\n",
    "safety_factor       = 1.\n",
    "parallel_iterations = NUM_CORES\n",
    "\n",
    "print('Discretization size: {}\\n'.format(lyapunov.discretization.nindex))\n",
    "\n",
    "try:\n",
    "    e         = len(level) - 1\n",
    "    level     = np.concatenate((level, np.zeros(safe_set_updates)))\n",
    "    safe_size = np.concatenate((safe_size, np.zeros(safe_set_updates)))\n",
    "    temp      = data_per_update * np.arange(1, safe_set_updates + 1) + data_size[-1]\n",
    "    data_size = np.concatenate((data_size, temp))\n",
    "except NameError:\n",
    "    e            = 0\n",
    "    level        = np.zeros(safe_set_updates + 1)\n",
    "    level[0]     = lyapunov.feed_dict[lyapunov.c_max]\n",
    "    safe_size    = np.zeros(safe_set_updates + 1)\n",
    "    safe_size[0] = np.sum(lyapunov.safe_set)\n",
    "    data_size    = data_per_update * np.arange(safe_set_updates + 1)\n",
    "    \n",
    "for i in range(safe_set_updates):\n",
    "    print('Iteration {} with c_max: {}'.format(e + i + 1, lyapunov.feed_dict[lyapunov.c_max]))\n",
    "\n",
    "    # TODO single-threaded bottleneck for large state spaces?\n",
    "    if data_per_update > 0:\n",
    "        start = time.time()\n",
    "        for _ in range(data_per_update): \n",
    "            update_gp()\n",
    "        end = time.time()\n",
    "        duration_gp = end - start\n",
    "        print('Duration (gp update, total): {}'.format(duration_gp))\n",
    "        print('Duration (gp update, avg): {}'.format(duration_gp / data_per_update))\n",
    "\n",
    "    start = time.time()\n",
    "    lyapunov.update_safe_set(batch_size, can_shrink, n_max, safety_factor, parallel_iterations)\n",
    "    end = time.time()\n",
    "    duration_lyap = end - start\n",
    "    print('Duration (safe set update): {}'.format(duration_lyap))\n",
    "    \n",
    "    level[e + i + 1] = lyapunov.feed_dict[lyapunov.c_max]\n",
    "    safe_size[e + i + 1] = np.sum(lyapunov.safe_set)\n",
    "    \n",
    "    num_data = lyapunov.dynamics.functions[0].X.shape[0]\n",
    "    num_safe = lyapunov.safe_set.sum()\n",
    "    \n",
    "    print(\"Data points collected: {}\".format(num_data))\n",
    "    print('Safe set size: {} ({:.2f}%)'.format(num_safe, 100 * num_safe / lyapunov.discretization.nindex))\n",
    "    print('Growth: {}'.format(num_safe - init_safe_set_size))\n",
    "    print(\"NEW C_MAX: {}\".format(lyapunov.feed_dict[lyapunov.c_max]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fontsize = 16\n",
    "plt.rc('font', size=fontsize)\n",
    "\n",
    "N = np.copy(lyapunov._n)\n",
    "num_states = len(N)\n",
    "num_refined_states = np.sum(N[N > 1] ** state_dim)\n",
    "print('Grid size:', num_states)\n",
    "print('Safe set size:', num_safe)\n",
    "print('Refined grids size:', num_refined_states)\n",
    "print('Effective total grid size:', num_refined_states + len(N[N <= 1]))\n",
    "print('Effective safe grid size:', num_refined_states + len(N[N == 1]))\n",
    "\n",
    "# debug(lyapunov, true_dynamics, state_norm, Nmax=n_max, plot='cartpole', fixed_state=(0., 0., 0., 0.))\n",
    "\n",
    "#\n",
    "grid = lyapunov.discretization\n",
    "vals, true_dv = session.run([values, dv], {states: grid.all_points})\n",
    "D = (true_dv < 0).ravel()\n",
    "V = (vals <= c_max).ravel()\n",
    "Vn = (vals <= lyapunov.feed_dict[lyapunov.c_max]).ravel()\n",
    "N[np.logical_and(Vn, N <= 0)] = 1\n",
    "N[N == 0] = -1\n",
    "\n",
    "# Snap fixed_state to the closest grid point\n",
    "fixed_state = np.asarray([0., 0., 0., 0.], dtype=OPTIONS.np_dtype)\n",
    "fixed_index = np.zeros_like(fixed_state, dtype=int)\n",
    "for d in range(grid.ndim):\n",
    "    fixed_index[d], fixed_state[d] = find_nearest(grid.discrete_points[d], fixed_state[d])\n",
    "\n",
    "# Get 2d-planes of the discretization (x vs. v, theta vs. omega) according to fixed_state\n",
    "planes = [[1, 3], [0, 2]]\n",
    "grid_slices = []\n",
    "for p in planes:\n",
    "    grid_slices.append(np.logical_and(grid.all_points[:, p[0]] == fixed_state[p[0]], \n",
    "                                      grid.all_points[:, p[1]] == fixed_state[p[1]]).ravel())\n",
    "    \n",
    "    \n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(8, 8), dpi=OPTIONS.dpi)\n",
    "fig2, ax2 = plt.subplots(1, 1, figsize=(8, 8), dpi=OPTIONS.dpi)\n",
    "\n",
    "for i, (p, mask, fig, ax) in enumerate(zip(planes[::-1], grid_slices, [fig1, fig2], [ax1, ax2])):\n",
    "    \n",
    "    z = D[mask].reshape(grid.num_points[p])\n",
    "    im = ax.imshow(z.T, origin='lower', extent=plot_limits[p].ravel(), aspect=plot_limits[p[0], 1] / plot_limits[p[1], 1], \n",
    "                   cmap=binary_cmap((0., 0., 0., 0.3)))\n",
    "#     z = V[mask].reshape(grid.num_points[p])\n",
    "#     im = ax.imshow(z.T, origin='lower', extent=plot_limits[p].ravel(), aspect=plot_limits[p[0], 1] / plot_limits[p[1], 1], \n",
    "#                    cmap=binary_cmap('blue', 0.3))\n",
    "    \n",
    "    z = N[mask].reshape(grid.num_points[p])\n",
    "    cmap = plt.get_cmap('viridis', lut=n_max)\n",
    "    cmap.set_over('gold')\n",
    "    cmap.set_under((1., 1., 1., 0.))\n",
    "    im = ax.imshow(z.T, origin='lower', extent=plot_limits[p].ravel(), aspect=plot_limits[p[0], 1] / plot_limits[p[1], 1], \n",
    "                   cmap=cmap, vmin=0, vmax=1000)\n",
    "    cbar = fig.colorbar(im, ax=ax, label=r'$N({\\bf x})$')\n",
    "    grid_string = (r'$M = {}$'.format(grid.num_points[0] - 1) \n",
    "               + ',  ' + r'$|\\mathcal{X}_\\tau|$ = ' + r'{:.1e}'.format((grid.num_points[0] - 1) ** grid.ndim) \n",
    "               + ',  ' + r'$\\tau$ = ' + r'{:.0e}'.format(np.sum(grid.unit_maxes) / 2))\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.set_title(r'$\\phi = \\dot{\\phi} = 0$' + '\\n' + grid_string, fontsize=fontsize)\n",
    "        ax.set_xlabel(r'$x$ [m]', labelpad=pad)\n",
    "        ax.set_ylabel(r'$\\dot{x}$ [m/s]', labelpad=pad)\n",
    "    else:\n",
    "        ax.set_title(r'$x = \\dot{x} = 0$' + '\\n' + grid_string, fontsize=fontsize)\n",
    "        ax.set_xlabel(r'$\\phi$ [deg]', labelpad=pad)\n",
    "        ax.set_ylabel(r'$\\dot{\\phi}$ [deg/s]', labelpad=pad)\n",
    "\n",
    "    #\n",
    "    initial_safe_set = lyapunov.initial_safe_set[mask].reshape(grid.num_points[p])\n",
    "    cmap = ListedColormap([(1., 1., 1., 0.), (1., 0., 0., 1)])\n",
    "    im = ax.imshow(initial_safe_set.T, origin='lower', extent=plot_limits[p].ravel(), aspect=plot_limits[p[0], 1] / plot_limits[p[1], 1], \n",
    "                   cmap=cmap, vmin=None, vmax=None)\n",
    "    \n",
    "    # Legend\n",
    "    colors = [(0., 0., 0., 0.3), 'red']\n",
    "    proxy = [plt.Rectangle((0,0), 1, 1, fc=c) for c in colors]\n",
    "    labels = [r'$\\mathcal{D}$', r'$\\mathcal{S}^{\\!\\ 0}_\\pi$']\n",
    "    ax.legend(proxy, labels, loc='upper right', fontsize=fontsize)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "if OPTIONS.save_figs:\n",
    "    fig1.savefig(OPTIONS.fig_path + 'cartpole_stability_safe_x.pdf', bbox_inches='tight')\n",
    "    fig2.savefig(OPTIONS.fig_path + 'cartpole_stability_safe_phi.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=8)\n",
    "stop = len(data_size)\n",
    "    \n",
    "fig, ax = plt.subplots(1, 2, sharex=False, figsize=(10, 3), dpi=300)\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.2)\n",
    "\n",
    "ax[0].step(data_size[:stop], level[:stop], 'o--', where='post')\n",
    "ax[0].set_xlabel(r'Number of data points collected', fontsize=12)\n",
    "ax[0].set_ylabel(r'$c_{max}$', fontsize=12)\n",
    "\n",
    "ax[1].step(data_size[:stop], safe_size[:stop], 'o--', where='post')\n",
    "ax[1].set_xlabel(r'Number of data points collected', fontsize=12)\n",
    "ax[1].set_ylabel(r'Safe set size', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(level)\n",
    "print(data_size)\n",
    "print(safe_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n    = np.array([0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1100, 1100])\n",
    "cmax = np.array([1.7935, 1.797, 1.797, 1.8433, 3.9234, 4.0195, 4.0214, 4.0214, 4.1209, 4.1209, 4.1209, 4.1209, 4.1209, 4.1209])\n",
    "safe = np.array([110491, 110847, 110847, 115307, 369831, 383585, 383865, 383865, 398003, 398003, 398003, 398003, 398003, 398003])\n",
    "grid = 6765201\n",
    "dv_  = 2619588\n",
    "vmax = 430693\n",
    "\n",
    "# Legend\n",
    "colors = ['red', 'blue']\n",
    "proxy = [plt.Rectangle((0,0), 1, 1, fc=c) for c in colors]\n",
    "labels = [r'$c = c_n$', r'$c = c_{max}$']\n",
    "\n",
    "#\n",
    "plt.rc('font', size=16)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5), dpi=100)\n",
    "ax.step(n, cmax, 'ro', where='post', linestyle='--')\n",
    "ax.set_xlabel(r'$n$')\n",
    "ax.set_ylabel(r'$c_n$')\n",
    "ax.set_ylim([1.5, 4.5])\n",
    "fig.savefig(OPTIONS.fig_path + 'cartpole_cn.pdf', bbox_inches='tight')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5), dpi=100)\n",
    "ax.step(n, safe / dv_, 'ro', where='post', linestyle='--')\n",
    "ax.plot(n, (vmax / dv_) * np.ones_like(n), 'b', linewidth=2)\n",
    "ax.set_xlabel(r'$n$')\n",
    "ax.set_ylabel(r'$|\\mathcal{V}(c) \\cap \\mathcal{X}_\\tau|\\ / \\ |\\mathcal{D} \\cap \\mathcal{X}_\\tau|$')\n",
    "ax.set_ylim([0.04, 0.18])\n",
    "ax.legend(proxy, labels, loc='lower right', fontsize=16)\n",
    "fig.savefig(OPTIONS.fig_path + 'cartpole_safesize.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(c_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
